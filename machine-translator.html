<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>machine-translator</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
[dir="rtl"] #ipython_notebook {
  float: right !important;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
[dir="rtl"] #tabs li {
  float: right;
}
ul#tabs {
  margin-bottom: 4px;
}
[dir="rtl"] ul#tabs {
  margin-right: 0px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons {
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-right {
  padding-top: 1px;
  float: left !important;
}
[dir="rtl"] .list_toolbar .pull-left {
  float: right !important;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
[dir="rtl"] #tree-selector a {
  float: right;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
[dir="rtl"] #new-menu {
  text-align: right;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
[dir="rtl"] #running .col-sm-8 {
  float: right !important;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Neural-Machine-Translator">Neural Machine Translator<a class="anchor-link" href="#Neural-Machine-Translator">&#194;&#182;</a></h1><p>In this notebook I will create the sequence-to-sequence translation system in Tensorflow. This will be done using single-layer encoder and decoder architecture, without using the Tensorflow native seq-to-seq modules. The method is heavily inspired by <a href="https://github.com/ematvey/tensorflow-seq2seq-tutorials">these tutorials</a>, particularly the implementation of previously fed tokens into the <code>tf.nn.raw_rnn</code> as proposed in the second tutorial. My code goes one step further and is able to feed in either the <em>ground truth</em>, previously generated tokens or a random combination of the two. While feeding in only the ground truth speeds up training and passing previously generated tokens increases robustness and performance, a combination of the two has been shown to interpolate between these two extremes. My NMT implementation was benchmarked against a direct dictionary based method using the <a href="https://pypi.python.org/pypi/googletrans">GoogleTrans</a> API.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-the-preprocessed-data">Loading the preprocessed data<a class="anchor-link" href="#Loading-the-preprocessed-data">&#194;&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">load_obj</span>

<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;logfile&quot;</span><span class="p">,</span> <span class="n">filemode</span><span class="o">=</span><span class="s2">&quot;a+&quot;</span><span class="p">,</span>
                        <span class="n">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)-15s</span><span class="s2"> </span><span class="si">%(levelname)-8s</span><span class="s2"> </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span>
<span class="n">lang_t</span> <span class="o">=</span> <span class="s1">&#39;en&#39;</span>
<span class="n">lang_s</span> <span class="o">=</span> <span class="s1">&#39;fr&#39;</span>
<span class="n">prep_path</span> <span class="o">=</span> <span class="s2">&quot;/DATA/&quot;</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
<span class="n">data_dict</span> <span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="n">prep_path</span><span class="o">+</span><span class="s1">&#39;data_dic&#39;</span><span class="p">)</span>
<span class="n">s_train</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;s_train&quot;</span><span class="p">]</span> <span class="c1"># preprocessed data</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;t_train&quot;</span><span class="p">]</span>
<span class="n">s_test</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;s_test&quot;</span><span class="p">]</span>
<span class="n">t_test</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;t_test&quot;</span><span class="p">]</span>
<span class="n">word2id_s</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;word2id_s&quot;</span><span class="p">]</span> <span class="c1"># word-to-ID dictionaries </span>
<span class="n">word2id_t</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;word2id_t&quot;</span><span class="p">]</span>
<span class="n">id2word_s</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;id2word_s&quot;</span><span class="p">]</span>
<span class="n">id2word_t</span> <span class="o">=</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;id2word_t&quot;</span><span class="p">]</span>

<span class="n">vocab_size_t</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2id_t</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="c1"># Includes UNK, EOS and PAD tokens</span>
<span class="n">vocab_size_s</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word2id_s</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">raw_s_test</span> <span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="n">prep_path</span><span class="o">+</span><span class="s2">&quot;source_test&quot;</span><span class="p">)</span> <span class="c1"># Data for benchmark model </span>
<span class="n">raw_t_test</span> <span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="n">prep_path</span><span class="o">+</span><span class="s2">&quot;target_test&quot;</span><span class="p">)</span> <span class="c1"># Data for benchmark model </span>
<span class="k">print</span> <span class="s2">&quot;Tokens in s_train are of type &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">s_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span> <span class="s2">&quot;Tokens in raw_s_train are of type &quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">raw_s_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span> <span class="s2">&quot;s_test and raw_s_test are the same length? : &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_test</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_s_test</span><span class="p">)</span>
<span class="k">print</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_test</span><span class="p">),</span>  <span class="nb">len</span><span class="p">(</span><span class="n">raw_s_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tokens in s_train are of type  &lt;type &#39;int&#39;&gt;
Tokens in raw_s_train are of type  &lt;type &#39;unicode&#39;&gt;
s_test and raw_s_test are the same length? :  True
17742 17742
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Benchmark-model">Benchmark model<a class="anchor-link" href="#Benchmark-model">&#194;&#182;</a></h2><p>Here I use the <a href="">GoogleTrans</a> python package to translate the corpus by translating each individual word in the text. There seems to be an issue with the number of JSON requests the model makes to the Google Translate service, so it needs to work in passes. If a phrase is skipped due to a JSON error, keep it stored and try again later (with a new Translator instance).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">googletrans</span> <span class="kn">import</span> <span class="n">Translator</span>


<span class="k">def</span> <span class="nf">googletrans_pass</span><span class="p">(</span><span class="n">s_text</span><span class="p">,</span> <span class="n">target_lang</span><span class="o">=</span><span class="s1">&#39;fr&#39;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; This function makes a single pass through the data and tries to </span>
<span class="sd">    translate each phrase one word at a time. Occasionally there are JSON</span>
<span class="sd">    errors, probably due to too many requests being made. In this case</span>
<span class="sd">    a new Translator instance is made and the failed attempts/skipped phrases</span>
<span class="sd">    are returned, to be attempted again.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">translator</span> <span class="o">=</span> <span class="n">Translator</span><span class="p">()</span>
    <span class="n">trans_corpus</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">skipped_phrases</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">phrase</span> <span class="ow">in</span> <span class="n">s_text</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">trans_corpus</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="p">[</span><span class="n">trans</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span>
                                <span class="n">trans</span> <span class="ow">in</span> <span class="n">translator</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span>
                                <span class="n">phrase</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="n">target_lang</span><span class="p">)]))</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="c1"># Making a new Translator instance seems to help JSON errors</span>
            <span class="n">translator</span> <span class="o">=</span> <span class="n">Translator</span><span class="p">()</span>
            <span class="n">skipped_phrases</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">phrase</span><span class="p">))</span>
            <span class="k">print</span> <span class="s2">&quot;{} for phrase {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">err</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">trans_corpus</span><span class="p">,</span> <span class="n">skipped_phrases</span>

<span class="k">def</span> <span class="nf">translate_word_by_word</span><span class="p">(</span><span class="n">source_text</span><span class="p">):</span>
    <span class="c1"># Need to keep track of phrase ordering by labelling</span>
    <span class="n">source_text</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">phr</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">phr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_text</span><span class="p">)]</span>
    <span class="n">trans_text</span><span class="p">,</span> <span class="n">skipped_phrases</span> <span class="o">=</span> <span class="n">googletrans_pass</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_lang</span><span class="o">=</span><span class="n">lang_t</span><span class="p">)</span>
    <span class="k">print</span> <span class="s2">&quot;There are {} phrases which could not be translated first time around.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                                                    <span class="nb">len</span><span class="p">(</span><span class="n">skipped_phrases</span><span class="p">))</span>
    <span class="c1"># Keep making passes until there are no more untranslated phrases left</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">skipped_phrases</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">translated_corpus</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">tc_s</span><span class="p">,</span> <span class="n">skipped_phrases</span> <span class="o">=</span> <span class="n">googletrans_pass</span><span class="p">(</span><span class="n">skipped_phrases</span><span class="p">,</span> <span class="n">target_lang</span><span class="o">=</span><span class="n">lang_t</span><span class="p">)</span>
        <span class="n">trans_text</span> <span class="o">+=</span> <span class="n">tc_s</span>
        <span class="k">print</span> <span class="s2">&quot;There are {} phrases which could not be translated in pass {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                                            <span class="nb">len</span><span class="p">(</span><span class="n">skipped_phrases</span><span class="p">),</span> <span class="n">j</span><span class="p">)</span>
        <span class="n">j</span><span class="o">+=</span><span class="mi">1</span>
    <span class="c1"># Sort the phrases via their labels.</span>
    <span class="c1"># Sorted function gives ([indices], [phrases]) so just need 2nd element</span>
    <span class="n">trans_text</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">BM_translated</span><span class="p">)))[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">trans_text</span>

<span class="c1"># Takes a while to run, running this cell is not for the faint hearted</span>
<span class="n">BM_translated</span> <span class="o">=</span> <span class="n">translate_word_by_word</span><span class="p">(</span><span class="n">raw_s_test</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;Corpus translated from {} to {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lang_s</span><span class="p">,</span> <span class="n">lang_t</span><span class="p">)</span>
<span class="n">save_obj</span><span class="p">(</span><span class="n">BM_translated</span><span class="p">,</span> <span class="s2">&quot;BM_translated&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>No JSON object could be decoded for phrase 320
No JSON object could be decoded for phrase 682
No JSON object could be decoded for phrase 1047
No JSON object could be decoded for phrase 1141
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-7-df2ead2d7b19&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span> 
<span class="ansi-green-intense-fg ansi-bold">     46</span> <span class="ansi-red-fg"># Takes a while to run, running this cell is not for the faint hearted</span>
<span class="ansi-green-fg">---&gt; 47</span><span class="ansi-red-fg"> </span>BM_translated <span class="ansi-blue-fg">=</span> translate_word_by_word<span class="ansi-blue-fg">(</span>raw_s_test<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     48</span> <span class="ansi-green-fg">print</span> <span class="ansi-blue-fg">&#34;Corpus translated from {} to {}&#34;</span><span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>lang_s<span class="ansi-blue-fg">,</span> lang_t<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     49</span> save_obj<span class="ansi-blue-fg">(</span>BM_translated<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#34;BM_translated&#34;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-7-df2ead2d7b19&gt;</span> in <span class="ansi-cyan-fg">translate_word_by_word</span><span class="ansi-blue-fg">(source_text)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>     <span class="ansi-red-fg"># Need to keep track of phrase ordering by labelling</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span>     source_text <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">(</span>i<span class="ansi-blue-fg">,</span> phr<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> i<span class="ansi-blue-fg">,</span> phr <span class="ansi-green-fg">in</span> enumerate<span class="ansi-blue-fg">(</span>source_text<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">---&gt; 29</span><span class="ansi-red-fg">     </span>trans_text<span class="ansi-blue-fg">,</span> skipped_phrases <span class="ansi-blue-fg">=</span> googletrans_pass<span class="ansi-blue-fg">(</span>source_text<span class="ansi-blue-fg">,</span> target_lang<span class="ansi-blue-fg">=</span>lang_t<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span>     print &#34;There are {} phrases which could not be translated first time around.&#34;.format(
<span class="ansi-green-intense-fg ansi-bold">     31</span>                                                                     len(skipped_phrases))

<span class="ansi-green-fg">&lt;ipython-input-7-df2ead2d7b19&gt;</span> in <span class="ansi-cyan-fg">googletrans_pass</span><span class="ansi-blue-fg">(s_text, target_lang)</span>
<span class="ansi-green-intense-fg ansi-bold">     16</span>             trans_corpus.append((i, [trans.text for
<span class="ansi-green-intense-fg ansi-bold">     17</span>                                 trans in translator.translate(
<span class="ansi-green-fg">---&gt; 18</span><span class="ansi-red-fg">                                 phrase, dest=target_lang)]))
</span><span class="ansi-green-intense-fg ansi-bold">     19</span>         <span class="ansi-green-fg">except</span> ValueError <span class="ansi-green-fg">as</span> err<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span>             <span class="ansi-red-fg"># Making a new Translator instance seems to help JSON errors</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/googletrans/client.pyc</span> in <span class="ansi-cyan-fg">translate</span><span class="ansi-blue-fg">(self, text, dest, src)</span>
<span class="ansi-green-intense-fg ansi-bold">    125</span>             result <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    126</span>             <span class="ansi-green-fg">for</span> item <span class="ansi-green-fg">in</span> text<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 127</span><span class="ansi-red-fg">                 </span>translated <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>translate<span class="ansi-blue-fg">(</span>item<span class="ansi-blue-fg">,</span> dest<span class="ansi-blue-fg">=</span>dest<span class="ansi-blue-fg">,</span> src<span class="ansi-blue-fg">=</span>src<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    128</span>                 result<span class="ansi-blue-fg">.</span>append<span class="ansi-blue-fg">(</span>translated<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    129</span>             <span class="ansi-green-fg">return</span> result

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/googletrans/client.pyc</span> in <span class="ansi-cyan-fg">translate</span><span class="ansi-blue-fg">(self, text, dest, src)</span>
<span class="ansi-green-intense-fg ansi-bold">    130</span> 
<span class="ansi-green-intense-fg ansi-bold">    131</span>         origin <span class="ansi-blue-fg">=</span> text
<span class="ansi-green-fg">--&gt; 132</span><span class="ansi-red-fg">         </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_translate<span class="ansi-blue-fg">(</span>text<span class="ansi-blue-fg">,</span> dest<span class="ansi-blue-fg">,</span> src<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    133</span> 
<span class="ansi-green-intense-fg ansi-bold">    134</span>         <span class="ansi-red-fg"># this code will be updated when the format is changed.</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/googletrans/client.pyc</span> in <span class="ansi-cyan-fg">_translate</span><span class="ansi-blue-fg">(self, text, dest, src)</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span>                                     token=token)
<span class="ansi-green-intense-fg ansi-bold">     60</span>         url <span class="ansi-blue-fg">=</span> urls<span class="ansi-blue-fg">.</span>TRANSLATE<span class="ansi-blue-fg">.</span>format<span class="ansi-blue-fg">(</span>host<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>_pick_service_url<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 61</span><span class="ansi-red-fg">         </span>r <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>session<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span>url<span class="ansi-blue-fg">,</span> params<span class="ansi-blue-fg">=</span>params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span> 
<span class="ansi-green-intense-fg ansi-bold">     63</span>         data <span class="ansi-blue-fg">=</span> utils<span class="ansi-blue-fg">.</span>format_json<span class="ansi-blue-fg">(</span>r<span class="ansi-blue-fg">.</span>text<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/requests/sessions.pyc</span> in <span class="ansi-cyan-fg">get</span><span class="ansi-blue-fg">(self, url, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    519</span> 
<span class="ansi-green-intense-fg ansi-bold">    520</span>         kwargs<span class="ansi-blue-fg">.</span>setdefault<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;allow_redirects&#39;</span><span class="ansi-blue-fg">,</span> True<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 521</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>request<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;GET&#39;</span><span class="ansi-blue-fg">,</span> url<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    522</span> 
<span class="ansi-green-intense-fg ansi-bold">    523</span>     <span class="ansi-green-fg">def</span> options<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> url<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/requests/sessions.pyc</span> in <span class="ansi-cyan-fg">request</span><span class="ansi-blue-fg">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="ansi-green-intense-fg ansi-bold">    506</span>         }
<span class="ansi-green-intense-fg ansi-bold">    507</span>         send_kwargs<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>settings<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 508</span><span class="ansi-red-fg">         </span>resp <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>send<span class="ansi-blue-fg">(</span>prep<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>send_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    509</span> 
<span class="ansi-green-intense-fg ansi-bold">    510</span>         <span class="ansi-green-fg">return</span> resp

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/requests/sessions.pyc</span> in <span class="ansi-cyan-fg">send</span><span class="ansi-blue-fg">(self, request, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    616</span> 
<span class="ansi-green-intense-fg ansi-bold">    617</span>         <span class="ansi-red-fg"># Send the request</span>
<span class="ansi-green-fg">--&gt; 618</span><span class="ansi-red-fg">         </span>r <span class="ansi-blue-fg">=</span> adapter<span class="ansi-blue-fg">.</span>send<span class="ansi-blue-fg">(</span>request<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    619</span> 
<span class="ansi-green-intense-fg ansi-bold">    620</span>         <span class="ansi-red-fg"># Total elapsed time of the request (approximately)</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/requests/adapters.pyc</span> in <span class="ansi-cyan-fg">send</span><span class="ansi-blue-fg">(self, request, stream, timeout, verify, cert, proxies)</span>
<span class="ansi-green-intense-fg ansi-bold">    438</span>                     decode_content<span class="ansi-blue-fg">=</span>False<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    439</span>                     retries<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>max_retries<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 440</span><span class="ansi-red-fg">                     </span>timeout<span class="ansi-blue-fg">=</span>timeout
<span class="ansi-green-intense-fg ansi-bold">    441</span>                 )
<span class="ansi-green-intense-fg ansi-bold">    442</span> 

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.pyc</span> in <span class="ansi-cyan-fg">urlopen</span><span class="ansi-blue-fg">(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    599</span>                                                   timeout<span class="ansi-blue-fg">=</span>timeout_obj<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    600</span>                                                   body<span class="ansi-blue-fg">=</span>body<span class="ansi-blue-fg">,</span> headers<span class="ansi-blue-fg">=</span>headers<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 601</span><span class="ansi-red-fg">                                                   chunked=chunked)
</span><span class="ansi-green-intense-fg ansi-bold">    602</span> 
<span class="ansi-green-intense-fg ansi-bold">    603</span>             <span class="ansi-red-fg"># If we&#39;re going to release the connection in ``finally:``, then</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.pyc</span> in <span class="ansi-cyan-fg">_make_request</span><span class="ansi-blue-fg">(self, conn, method, url, timeout, chunked, **httplib_request_kw)</span>
<span class="ansi-green-intense-fg ansi-bold">    378</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    379</span>             <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>  <span class="ansi-red-fg"># Python 2.7, use buffering of HTTP responses</span>
<span class="ansi-green-fg">--&gt; 380</span><span class="ansi-red-fg">                 </span>httplib_response <span class="ansi-blue-fg">=</span> conn<span class="ansi-blue-fg">.</span>getresponse<span class="ansi-blue-fg">(</span>buffering<span class="ansi-blue-fg">=</span>True<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    381</span>             <span class="ansi-green-fg">except</span> TypeError<span class="ansi-blue-fg">:</span>  <span class="ansi-red-fg"># Python 2.6 and older, Python 3</span>
<span class="ansi-green-intense-fg ansi-bold">    382</span>                 <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc</span> in <span class="ansi-cyan-fg">getresponse</span><span class="ansi-blue-fg">(self, buffering)</span>
<span class="ansi-green-intense-fg ansi-bold">   1134</span> 
<span class="ansi-green-intense-fg ansi-bold">   1135</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1136</span><span class="ansi-red-fg">             </span>response<span class="ansi-blue-fg">.</span>begin<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1137</span>             <span class="ansi-green-fg">assert</span> response<span class="ansi-blue-fg">.</span>will_close <span class="ansi-blue-fg">!=</span> _UNKNOWN
<span class="ansi-green-intense-fg ansi-bold">   1138</span>             self<span class="ansi-blue-fg">.</span>__state <span class="ansi-blue-fg">=</span> _CS_IDLE

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc</span> in <span class="ansi-cyan-fg">begin</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    451</span>         <span class="ansi-red-fg"># read until we get a non-100 response</span>
<span class="ansi-green-intense-fg ansi-bold">    452</span>         <span class="ansi-green-fg">while</span> True<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 453</span><span class="ansi-red-fg">             </span>version<span class="ansi-blue-fg">,</span> status<span class="ansi-blue-fg">,</span> reason <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_read_status<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    454</span>             <span class="ansi-green-fg">if</span> status <span class="ansi-blue-fg">!=</span> CONTINUE<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    455</span>                 <span class="ansi-green-fg">break</span>

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc</span> in <span class="ansi-cyan-fg">_read_status</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    407</span>     <span class="ansi-green-fg">def</span> _read_status<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    408</span>         <span class="ansi-red-fg"># Initialize with Simple-Response defaults</span>
<span class="ansi-green-fg">--&gt; 409</span><span class="ansi-red-fg">         </span>line <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>fp<span class="ansi-blue-fg">.</span>readline<span class="ansi-blue-fg">(</span>_MAXLINE <span class="ansi-blue-fg">+</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    410</span>         <span class="ansi-green-fg">if</span> len<span class="ansi-blue-fg">(</span>line<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">&gt;</span> _MAXLINE<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    411</span>             <span class="ansi-green-fg">raise</span> LineTooLong<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;header line&#34;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/socket.pyc</span> in <span class="ansi-cyan-fg">readline</span><span class="ansi-blue-fg">(self, size)</span>
<span class="ansi-green-intense-fg ansi-bold">    478</span>             <span class="ansi-green-fg">while</span> True<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    479</span>                 <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 480</span><span class="ansi-red-fg">                     </span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_sock<span class="ansi-blue-fg">.</span>recv<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_rbufsize<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    481</span>                 <span class="ansi-green-fg">except</span> error<span class="ansi-blue-fg">,</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    482</span>                     <span class="ansi-green-fg">if</span> e<span class="ansi-blue-fg">.</span>args<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">==</span> EINTR<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ssl.pyc</span> in <span class="ansi-cyan-fg">recv</span><span class="ansi-blue-fg">(self, buflen, flags)</span>
<span class="ansi-green-intense-fg ansi-bold">    754</span>                     <span class="ansi-blue-fg">&#34;non-zero flags not allowed in calls to recv() on %s&#34;</span> <span class="ansi-blue-fg">%</span>
<span class="ansi-green-intense-fg ansi-bold">    755</span>                     self.__class__)
<span class="ansi-green-fg">--&gt; 756</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>read<span class="ansi-blue-fg">(</span>buflen<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    758</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_sock<span class="ansi-blue-fg">.</span>recv<span class="ansi-blue-fg">(</span>buflen<span class="ansi-blue-fg">,</span> flags<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/ssl.pyc</span> in <span class="ansi-cyan-fg">read</span><span class="ansi-blue-fg">(self, len, buffer)</span>
<span class="ansi-green-intense-fg ansi-bold">    641</span>                 v <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_sslobj<span class="ansi-blue-fg">.</span>read<span class="ansi-blue-fg">(</span>len<span class="ansi-blue-fg">,</span> buffer<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    642</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 643</span><span class="ansi-red-fg">                 </span>v <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_sslobj<span class="ansi-blue-fg">.</span>read<span class="ansi-blue-fg">(</span>len<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    644</span>             <span class="ansi-green-fg">return</span> v
<span class="ansi-green-intense-fg ansi-bold">    645</span>         <span class="ansi-green-fg">except</span> SSLError <span class="ansi-green-fg">as</span> x<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluation-metric:-----BLEU-Score">Evaluation metric:     BLEU Score<a class="anchor-link" href="#Evaluation-metric:-----BLEU-Score">&#194;&#182;</a></h2><p>Here I use the NLTK implementation of BLEU score to measure how successful the machine translation was.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.translate</span> <span class="kn">import</span> <span class="n">bleu_score</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">remove_EOS_PAD</span>

<span class="n">p_phrase1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">t_phrase</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">76</span><span class="p">,</span> <span class="mi">87</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="c1"># Truncate sequences at [1]</span>
<span class="n">t_phrase</span> <span class="o">=</span> <span class="n">remove_EOS_PAD</span><span class="p">(</span><span class="n">t_phrase</span><span class="p">)</span>
<span class="n">p_phrase1</span> <span class="o">=</span> <span class="n">remove_EOS_PAD</span><span class="p">(</span><span class="n">p_phrase1</span><span class="p">)</span>

<span class="k">print</span> <span class="s2">&quot;BLEU1 score test is {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">([[</span><span class="n">t_phrase</span><span class="p">]],</span> <span class="p">[</span><span class="n">p_phrase1</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">])))</span>
<span class="k">print</span> <span class="s2">&quot;BLEU2 score test is {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">([[</span><span class="n">t_phrase</span><span class="p">]],</span> <span class="p">[</span><span class="n">p_phrase1</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>BLEU1 score test is 0.282160574964.
BLEU2 score test is 0.218560641558.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#test_targets = [[ids_to_phrases(phrase,id_to_word_t)]for phrase in test_t]</span>

<span class="n">BM_BLEU4</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">test_targets</span><span class="p">,</span> <span class="n">BM_translated</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span>
                                                            <span class="mf">0.25</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">BM_BLEU2</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">test_targets</span><span class="p">,</span> <span class="n">BM_translated</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))</span>
<span class="n">BM_BLEU1</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">test_targets</span><span class="p">,</span> <span class="n">BM_translated</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="k">print</span> <span class="s2">&quot;Actual: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_targets</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;Prediction: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BM_translated_corp</span><span class="p">[</span><span class="mi">10</span><span class="p">]))</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;Unigram BLEU score is {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">BM_BLEU1</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;Bigram BLEU score is {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">BM_BLEU2</span><span class="p">)</span>
<span class="k">print</span> <span class="s2">&quot;4-Gram BLEU: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">BM_BLEU4</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="The-Neural-Network">The Neural Network<a class="anchor-link" href="#The-Neural-Network">&#194;&#182;</a></h1><p>For development reasons I will use a much smaller dataset, using only 10% of the available data to test functionality.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[63]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">testing_only</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">load_embeddings</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># Do we want to load in the embeddings?</span>
<span class="n">plot_name</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">feed_previous_probability</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">anneal_feed_previous</span> <span class="o">=</span> <span class="bp">False</span>
<span class="n">encoder_hidden_units</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">epochs</span> <span class="o">=</span>  <span class="mi">45</span> <span class="c1"># How many times we loop over the whole training data</span>

<span class="n">GPU</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">prepend</span> <span class="o">=</span> <span class="s2">&quot;short_nmt/&quot;</span>
<span class="n">device_1</span> <span class="o">=</span> <span class="s2">&quot;gpu:0&quot;</span>
<span class="n">device_2</span> <span class="o">=</span> <span class="n">device_1</span>
<span class="n">data_path</span> <span class="o">=</span><span class="n">prep_path</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">GPU</span><span class="p">:</span>
    <span class="c1">#prepend = &#39;&#39;</span>
    
    <span class="n">device_1</span> <span class="o">=</span> <span class="s2">&quot;cpu:0&quot;</span>
    <span class="n">device_1</span> <span class="o">=</span> <span class="s2">&quot;cpu:1&quot;</span>
    <span class="n">data_path</span> <span class="o">=</span> <span class="s2">&quot;DATA/&quot;</span>


<span class="c1">#dev_fraction = 0.1</span>
<span class="c1">#test_fraction = 0.05</span>

<span class="n">log_dir</span> <span class="o">=</span> <span class="n">prepend</span><span class="o">+</span><span class="n">plot_name</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">prepend</span><span class="o">+</span><span class="s1">&#39;logfile&#39;</span><span class="o">+</span><span class="n">plot_name</span><span class="p">,</span> <span class="n">filemode</span><span class="o">=</span><span class="s2">&quot;a+&quot;</span><span class="p">,</span>
                        <span class="n">format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%(asctime)-15s</span><span class="s2"> </span><span class="si">%(levelname)-8s</span><span class="s2"> </span><span class="si">%(message)s</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loading-pretrained-embeddings">Loading pretrained embeddings<a class="anchor-link" href="#Loading-pretrained-embeddings">&#194;&#182;</a></h2><p>Go through each word in the vocabulary and find the pretrained word embedding in the polyglot pickle file. If one doesn't exist, initialise to a random distribution.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">def</span> <span class="nf">get_embeddings</span><span class="p">(</span><span class="n">id_to_word</span><span class="p">,</span> <span class="n">lang</span><span class="p">):</span>
    <span class="c1"># We load pretrained word2vec embeddings from polyglot to save on training time</span>
    <span class="n">filename</span> <span class="o">=</span><span class="n">data_path</span><span class="o">+</span><span class="s1">&#39;polyglot-&#39;</span><span class="o">+</span><span class="n">lang</span><span class="o">+</span><span class="s1">&#39;.pkl&#39;</span>
    <span class="n">pretrain_vocab</span><span class="p">,</span> <span class="n">pretrain_embed</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">))</span>
    <span class="c1"># Embeddings for &lt;PAD&gt; and &lt;EOS&gt; already exist  - find them first</span>
    <span class="n">embed_vocab</span> <span class="o">=</span> <span class="p">[</span><span class="n">pretrain_embed</span><span class="p">[</span><span class="n">pretrain_vocab</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">)],</span> <span class="n">pretrain_embed</span><span class="p">[</span><span class="n">pretrain_vocab</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;&lt;/S&gt;&#39;</span><span class="p">)]]</span>
    <span class="n">skip_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">skipped_words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="sa">u</span><span class="s1">&#39;&lt;PAD&gt;</span><span class="se">\n</span><span class="s1">&lt;EOS&gt;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="c1"># For tensorboard embeddings</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">id_to_word</span><span class="o">.</span><span class="n">items</span><span class="p">()[</span><span class="mi">2</span><span class="p">::]):</span>
        <span class="n">metadata</span> <span class="o">+=</span> <span class="n">word</span><span class="o">+</span><span class="sa">r</span><span class="s2">&quot;\n&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">pretrain_idx</span> <span class="o">=</span> <span class="n">pretrain_vocab</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="n">embed_vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pretrain_embed</span><span class="p">[</span><span class="n">pretrain_idx</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># it could be that the word is a name which needs to</span>
                <span class="c1"># be capitalized. Try this...</span>
                <span class="n">pretrain_idx</span> <span class="o">=</span> <span class="n">pretrain_vocab</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">title</span><span class="p">()))</span>
                <span class="n">embed_vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pretrain_embed</span><span class="p">[</span><span class="n">pretrain_idx</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># it could be that the word is an achronym which needs to</span>
                    <span class="c1"># be upper case. Try this...</span>
                    <span class="n">pretrain_idx</span> <span class="o">=</span> <span class="n">pretrain_vocab</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">upper</span><span class="p">())</span>
                    <span class="n">embed_vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pretrain_embed</span><span class="p">[</span><span class="n">pretrain_idx</span><span class="p">])</span>
                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="c1"># Give up trying to find an embedding.</span>
                    <span class="c1"># How many words are skipped? Which ones?</span>
                    <span class="n">skip_count</span> <span class="o">+=</span><span class="mi">1</span>
                    <span class="n">skipped_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
                    <span class="c1"># Let&#39;s just initialise the embedding to a random normal distribution</span>
                    <span class="n">embed_vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">64</span><span class="p">))</span>

    <span class="n">embed_vocab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embed_vocab</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">print</span> <span class="s2">&quot;The embedding matrix for {} has {} columns and {} rows.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span>
                                                <span class="n">embed_vocab</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embed_vocab</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">print</span> <span class="s2">&quot;{} vocab words were not in the {} embeddings file.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">skip_count</span><span class="p">,</span> <span class="n">lang</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">embed_vocab</span><span class="p">,</span> <span class="n">skipped_words</span><span class="p">,</span> <span class="n">metadata</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[65]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">def</span> <span class="nf">variable_summaries</span><span class="p">(</span><span class="n">var</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Attach a lot of summaries to a Tensor (for TensorBoard visualization).</span>
<span class="sd">  I&#39;ll just get as much data as I can.&quot;&quot;&quot;</span>
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;summaries&#39;</span><span class="p">):</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;stddev&#39;</span><span class="p">):</span>
      <span class="n">stddev</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">var</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;stddev&#39;</span><span class="p">,</span> <span class="n">stddev</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="s1">&#39;histogram&#39;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1"># the ith word in words corresponds to the ith embedding</span>
<span class="n">embed_vocab_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">vocab_size_s</span><span class="p">,</span> <span class="mi">64</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">embed_vocab_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">vocab_size_t</span><span class="p">,</span> <span class="mi">64</span><span class="p">)),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">metadata_s</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="n">metadata_t</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<span class="c1"># We only want to load in the embeddings, running this with test_only=True </span>
<span class="c1"># takes a while with the full dataset</span>

<span class="k">if</span> <span class="n">load_embeddings</span><span class="p">:</span>
    <span class="n">embed_vocab_s</span><span class="p">,</span> <span class="n">skipped_s</span><span class="p">,</span> <span class="n">metadata_s</span> <span class="o">=</span> <span class="n">get_embeddings</span><span class="p">(</span><span class="n">id2word_s</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="n">lang_s</span><span class="p">)</span>
    <span class="n">embed_vocab_t</span><span class="p">,</span> <span class="n">skipped_t</span><span class="p">,</span> <span class="n">metadata_t</span> <span class="o">=</span> <span class="n">get_embeddings</span><span class="p">(</span><span class="n">id2word_t</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="n">lang_t</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_1</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;source_embeddings&quot;</span><span class="p">):</span>
        <span class="c1"># Load encoder embeddings into trainable tensors</span>
        <span class="n">source_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">embed_vocab_s</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;source_embeddings&quot;</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">source_embeddings</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;target_embeddings&quot;</span><span class="p">):</span>
        <span class="c1"># Load decoder embeddings into trainable tensors</span>
        <span class="n">target_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">embed_vocab_t</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;target_embeddings&quot;</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">target_embeddings</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Building-the-encoder-layer">Building the encoder layer<a class="anchor-link" href="#Building-the-encoder-layer">&#194;&#182;</a></h2><p>With each forward pass a batch of phrases is fed through the neural network, one word at a time, so for the purposes of building the sequence-to-sequence model it helps to think of just a single batch.  The encoder inputs are going to be in the form of a tensor filled with word indices, of dimension <code>(encoder_max_time, batch size)</code> where maximum time is the length of the longest sequence in the batch. The batch size (though unusual) and maximum time step can change between batches so can be designated as <code>None</code> in the Tensorflow placeholder dimension. Similarly, the decoder inputs are of dimension <code>(decoder_max_time, batch_size)</code> where <code>decoder_max_time</code> does not need to equal <code>encoder_max_time</code> but must be the dimension of both the inputs and targets of the decoder. This is because at each timestep during training we must assess the quality of a single output slice (in time) of the decoder given a decoder input slice and some target sequence, therefore there must be valid tokens to compare at each time-step. If an output sequence is shorter than the target it is padded with zeros until it is the same length. Time will run down the columns of the input matrices which is called "time-major" format.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[67]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_1</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;encoder_inputs&#39;</span><span class="p">):</span>
        <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;encoder_inputs&#39;</span><span class="p">)</span>
        <span class="n">encoder_inputs_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;encoder_inputs_length&#39;</span><span class="p">)</span>


    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;decoder_targets&#39;</span><span class="p">):</span>
        <span class="n">decoder_targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;decoder_targets&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;decoder_inputs&#39;</span><span class="p">):</span>
        <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;decoder_inputs&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we find the embeddings which correspond to the words at each timestep. The words which were previously index integers for each sample in a batch/timestep, are used to index the columns of an embedding matrix. Using these column vectors as representations of the words means that the input matrices become tensors of dimension `(max_time_step, batch_size, embedding_hidden_dimension)'.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[68]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_1</span><span class="p">):</span>    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;encoder_inputs_embed&#39;</span><span class="p">):</span>
        <span class="n">encoder_inputs_embedded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">source_embeddings</span><span class="p">,</span>
                                                <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;encoder_inputs_embed&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;decoder_inputs_embed&#39;</span><span class="p">):</span>
        <span class="n">decoder_inputs_embedded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">target_embeddings</span><span class="p">,</span>
                                                <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;decoder_inputs_embed&#39;</span><span class="p">)</span>
    
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now the encoder RNN is finally constructed, using an LSTM which is unrolled over the encoder time-steps dynamically using <code>tf.nn.dynamic_rnn</code>. Notive that the keyword argument <code>time_major = True</code>  accounts for the fact that time-steps were defined along the columns of the input matrices.</p>
<p>The encoder RNN returns the encoder outputs - which are not used at all in sequence-to-sequence learning - and the final hidden state. This hidden state eventually becomes the first hidden state of the decoder layer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_1</span><span class="p">):</span>     
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;encoder_rnn&#39;</span><span class="p">):</span>
        <span class="n">encoder_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">encoder_hidden_units</span><span class="p">)</span>

        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">encoder_cell</span><span class="p">,</span> 
                                        <span class="n">encoder_inputs_embedded</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                                        <span class="n">time_major</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;encoder_rnn&#39;</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">encoder_final_state</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[70]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">decoder_hidden_units</span> <span class="o">=</span> <span class="n">encoder_hidden_units</span> <span class="c1"># Set these to be the same at the moment</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-decoder-layer:-raw_rnn">The decoder layer: <code>raw_rnn</code><a class="anchor-link" href="#The-decoder-layer:-raw_rnn">&#194;&#182;</a></h2><p>Now for the subtle part. Ideally we would like to have control over precisely what the decoder inputs are at each time-step, however <code>dynamic_rnn</code> has a relatively constrained API, so all inputs must be specified at the initial time-step. This means that we cannot feed tokens generated at the current time-step in as inputs in the next timestep. This actually makes it impossible to make adequate precictions with the model, since a generative model must <em>see</em> the data it has produced in order to react accordingly, in real-time. In order to implement this, I define a <em>loop function</em> for a <code>raw_rnn</code> which replicates the functionality of <code>dynamic_rnn</code>, which allowing for the feeding of previously generated tokens into the decoder inputs. I also allow the user to define a probability with which the previously generated tokens are mixed in with the "ground truth" target data, so that the model can be conditioned on a statistical mixture of both inputs. Since the length of the decoder max timesteps is unknown at the beginning of training, this has to be defined somehow so I just set it to the length of the encoder inputs plus some extra timesteps to allow for some error. This could be set to the decoder targets but strictly speaking this length would not be known in a blind test.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[71]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">reverse_encoder_inputs</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">additional_decode_steps</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># Includes the extra step for the leading EOS token</span>


<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_2</span><span class="p">):</span>
    <span class="n">encoder_max_time</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">))</span>
    <span class="n">decoder_lengths</span> <span class="o">=</span> <span class="n">encoder_inputs_length</span> <span class="o">+</span> <span class="n">additional_decode_steps</span>
    <span class="c1"># This is the projection layer, needed at every timestep because there is a possibility</span>
    <span class="c1"># of feeding previous tokens in.</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">decoder_hidden_units</span><span class="p">,</span> <span class="n">vocab_size_t</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1">#bias</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">vocab_size_t</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># The probability that we feed previous tokens in as decoder inputs</span>
    <span class="c1"># 0 = use ground truth training examples as inputs</span>
    <span class="n">feed_previous_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;feed_previous_prob&#39;</span><span class="p">)</span>
    
    <span class="c1"># Create a slice in time of PAD - for padding entire batch once all the sequences have</span>
    <span class="c1"># terminated. Also slice for EOS which is used to initialise the loop_function</span>
    <span class="n">eos_time_slice</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;EOS&#39;</span><span class="p">)</span>
    <span class="n">pad_time_slice</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;PAD&#39;</span><span class="p">)</span>

    <span class="c1">#retrieves columns of the embedding matrix. Dim= (batch_size, hidden_dim)</span>
    <span class="n">eos_step_embedded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embed_vocab_t</span><span class="p">,</span> <span class="n">eos_time_slice</span><span class="p">)</span>
    <span class="n">pad_step_embedded</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">embed_vocab_t</span><span class="p">,</span> <span class="n">pad_time_slice</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The loop function tells the RNN what to do and which quantities to manipulate at each timestep. If the model is feeding previously generated tokens in as decoder inputs it will have to pass the RNN output through a linear layer and find the argmax. Intially the hidden state will be set to the final state of the encoder and the initial input will be the <code>&lt;EOS&gt;</code> token. These are then mapped onto the inputs for the next timestep within <code>loop_fn</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[72]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_2</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">loop_fn_initial</span><span class="p">():</span>
        <span class="n">initial_elements_finished</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&gt;=</span> <span class="n">decoder_lengths</span><span class="p">)</span>  <span class="c1"># Returns false unless something is wrong</span>
        
        <span class="n">initial_input</span> <span class="o">=</span> <span class="n">eos_step_embedded</span>
        <span class="c1"># Self explanatory...</span>
        <span class="n">initial_cell_state</span> <span class="o">=</span> <span class="n">encoder_final_state</span>
        <span class="c1"># Not sure what these </span>
        <span class="n">initial_cell_output</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="c1">#none</span>
        <span class="n">initial_loop_state</span> <span class="o">=</span> <span class="bp">None</span>  <span class="c1"># we don&#39;t need to pass any additional information</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">initial_elements_finished</span><span class="p">,</span> <span class="c1"># Boolean</span>
                <span class="n">initial_input</span><span class="p">,</span> <span class="c1"># EOS</span>
                <span class="n">initial_cell_state</span><span class="p">,</span> <span class="c1"># encoder state</span>
                <span class="n">initial_cell_output</span><span class="p">,</span> <span class="c1"># The output to store for this state</span>
                <span class="n">initial_loop_state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loop_fn_transition</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">previous_output</span><span class="p">,</span> <span class="n">previous_state</span><span class="p">,</span> <span class="n">previous_loop_state</span><span class="p">):</span>
        <span class="c1"># What to do when moving from one time-step to the next</span>
        <span class="k">def</span> <span class="nf">feed_previous</span><span class="p">():</span>
             <span class="c1"># We take the previous output word vectors and apply the linear layer</span>
             <span class="c1"># to each output word in the batch</span>
            <span class="n">output_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">previous_output</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">b</span><span class="p">)</span>
            <span class="c1"># Greedily gives the index of the word with the highest probability</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Find embedding for the predicted word</span>
            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">source_embeddings</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">feed_ground_truth</span><span class="p">():</span>
            <span class="c1"># Find the current word in the shifted ground truth decoder targets</span>
            <span class="c1"># At initialisation, time=0. Therefore, decoder inputs are passed</span>
            <span class="c1"># here with a leading &lt;EOS&gt; token as usual.</span>
            <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">target_embeddings</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">get_next_input</span><span class="p">():</span>
            <span class="c1"># if uniform random number &lt; fpp, feed_previous. If not feed decoder target.</span>
            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span><span class="o">&lt;</span><span class="n">feed_previous_prob</span><span class="p">,</span> 
                            <span class="n">feed_previous</span><span class="p">,</span> <span class="n">feed_ground_truth</span><span class="p">)</span>

        <span class="c1"># boolean tensor of [batch_size] indicating if all of the sequences have finished</span>
        <span class="n">sequences_finished</span> <span class="o">=</span> <span class="p">(</span><span class="n">time</span> <span class="o">&gt;=</span> <span class="n">decoder_lengths</span><span class="p">)</span>
        <span class="c1">#Computes the &quot;logical and&quot; of elements to produce scalar</span>
        <span class="n">finished</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_all</span><span class="p">(</span><span class="n">sequences_finished</span><span class="p">)</span>
        <span class="c1"># If sequences are finished PAD, if not get next input</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">finished</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">pad_step_embedded</span><span class="p">,</span> <span class="n">get_next_input</span><span class="p">)</span>

        <span class="c1"># states and outputs are passed through </span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">previous_state</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">previous_output</span>
        <span class="n">loop_state</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">sequences_finished</span><span class="p">,</span>
                <span class="nb">input</span><span class="p">,</span>
                <span class="n">state</span><span class="p">,</span>
                <span class="n">output</span><span class="p">,</span>
                <span class="n">loop_state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loop_fn</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">previous_output</span><span class="p">,</span> <span class="n">previous_state</span><span class="p">,</span> <span class="n">previous_loop_state</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">previous_state</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>    <span class="c1"># time == 0</span>
            <span class="k">assert</span> <span class="n">previous_output</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">and</span> <span class="n">previous_state</span> <span class="ow">is</span> <span class="bp">None</span>
            <span class="k">return</span> <span class="n">loop_fn_initial</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># time &gt;0</span>
            <span class="k">return</span> <span class="n">loop_fn_transition</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">previous_output</span><span class="p">,</span> <span class="n">previous_state</span><span class="p">,</span> <span class="n">previous_loop_state</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now the loop function has been defined, we can create the <code>raw_rnn</code>. Within the loop function we found word predictions at each timestep, which required projecting onto the vocabulary space to find a word (embedding).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_2</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;decoder_rnn&#39;</span><span class="p">):</span>
        <span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">decoder_hidden_units</span><span class="p">)</span>
        <span class="n">decoder_outputs_</span><span class="p">,</span> <span class="n">decoder_final_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">raw_rnn</span><span class="p">(</span><span class="n">decoder_cell</span><span class="p">,</span> <span class="n">loop_fn</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;decoder_rnn&#39;</span><span class="p">)</span>
        <span class="c1"># Turn the output matrices dims=(batch_size, dec_hidden_layer_dim)</span>
        <span class="c1"># at each timestep into a tensor</span>
        <span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">decoder_outputs_</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">decoder_final_state</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Forward-and-backward-steps">Forward and backward steps<a class="anchor-link" href="#Forward-and-backward-steps">&#194;&#182;</a></h2><p>In the previous cell, outputs from the <code>raw_rnn</code> were seen to form a tensor of dimension <code>(max_decoder_time, batch_size, dec_hidden_dim</code> since the outputs are for each sequence in the batch at each timestep are word embeddings. These need to be turned into sequences of word IDs, so in order to do so we flatten the tensor to have dimension  <code>(max_decoder_time*batch_size, hidden_dim)</code> so it can be passed through the projection layer to discriminate which word it respresents, ending up with dimension <code>(max_decoder_time*batch_size, vocab_site_t)</code>. Then after reshaping this to a tensor of shape <code>(max_decoder_time, batch_size, vocab_site_t)</code> gives us the logits/scores for each word and an argmax is performed over the vocabulary words to generate the predictions. Note it is not necessary to perform softmax because the this function preserves ordering of the elements, so <code>max(softmax(v)) = max(v)</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_2</span><span class="p">):</span>  
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;projection_layer&#39;</span><span class="p">):</span>
        <span class="c1"># Get dimension information for the batch</span>
        <span class="n">decoder_max_steps</span><span class="p">,</span> <span class="n">decoder_batch_size</span><span class="p">,</span> <span class="n">decoder_dim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">unstack</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">))</span>
        <span class="c1"># flatten output tensor to pass through fully connected layer</span>
        <span class="n">decoder_outputs_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">))</span>
        <span class="c1"># output is a vector of dimension: vocab_size_t</span>
        <span class="n">decoder_logits_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">decoder_outputs_flat</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">b</span><span class="p">)</span>
        <span class="c1">#prediction vals</span>
        <span class="n">decoder_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">decoder_logits_flat</span><span class="p">,</span> <span class="p">(</span><span class="n">decoder_max_steps</span><span class="p">,</span> <span class="n">decoder_batch_size</span><span class="p">,</span> <span class="n">vocab_size_t</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;prediction&#39;</span><span class="p">):</span>
        <span class="n">decoder_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">decoder_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have the likelihood scores for each word in <code>decoder_logits</code> we calculate the probability distribution via a softmax and then find the cross-entropy, which calculates how well the predictions correlate with the targets and sum over all the timesteps. The mean of cross-entropy is then taken over the batch. That is the end of one forward step.</p>
<p>A backward step is then made by attempting to minimize the average cross-entropy (same as maximizing the log likelihood) using AdaM optimiser.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[75]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device_2</span><span class="p">):</span>     
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;timestep_cross_entropy&#39;</span><span class="p">):</span>
        <span class="n">timestep_cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
                                            <span class="n">labels</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">decoder_targets</span><span class="p">,</span>
                                            <span class="n">depth</span><span class="o">=</span><span class="n">vocab_size_t</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                                            <span class="n">logits</span><span class="o">=</span><span class="n">decoder_logits</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">timestep_cross_entropy</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">timestep_cross_entropy</span>
    <span class="c1"># loss is the mean of the cross entropy</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">timestep_cross_entropy</span><span class="p">)</span>
        <span class="n">variable_summaries</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="c1"># We use AdaM which combines AdaGrad (parameters updated less often get updated more 	strongly)</span>
    <span class="c1"># and momentum (updates depend on the slope of previous updates - avoiding local minima)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;Optimizer&#39;</span><span class="p">):</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Tensor(&#34;timestep_cross_entropy/Reshape_2:0&#34;, shape=(?, ?), dtype=float32, device=/device:GPU:0)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Feeding-data-into-the-model">Feeding data into the model<a class="anchor-link" href="#Feeding-data-into-the-model">&#194;&#182;</a></h2><p>A few functions are needed to help pass data efficiently to the sequence-to-sequence model. Firstly the source and target data needs to be efficiently split up into batches. Secondly this data needs to be formatted (another function in utils called <code>format_batch</code>) and fed into the model. Since $1)$ the lengths of decoder_inputs are being generated dynamically depending on the <code>encoder_input_lengths</code> and $2)$ the length decoder_inputs must be equal to the that of decoder_outputs, the formatting of these matrices must be done carefully to make sure the time axes are match in length. The <code>decoder_inputs</code> should also be shifted one timestep to the right, since the initial input is an <code>&lt;EOS&gt;</code> embedding. <code>encoder_input_lengths</code> changes between batches as well, so we feed the placeholders with these values too. Finally, the <code>feed_previous_probability</code> if free to change between batches too, since it could be useful for this number to grow or shrink over time - something that I will explore in the future.</p>
<p><strong> The encoder inputs were also reversed, as this has been shown to speed up training time substantially in language translation models.</strong> For example, rather than translating from $[a, b, c] \to [\alpha, \beta, \gamma]$ the source sequences are reversed: $[c, b, a] \to [\alpha, \beta, \gamma]$ so that $a$ and $\alpha$ are in close proximity in time. This is a main theoretical contribution of <a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">this paper</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[76]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">format_batch</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">format_batch() takes inputs with the number of cols as sequence length and </span>
<span class="sd">num of rows as batch size to the number of rows being the max sequence </span>
<span class="sd">length/ num cols being batch size</span>
<span class="sd">Essentially like a padding and then transpose&quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">batch_source_target</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">start</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>
        <span class="c1">#print type(source[start:end])</span>
        <span class="c1">#print len(target[start:end])</span>
        <span class="k">yield</span> <span class="n">source</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span> <span class="n">target</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">make_feed_dict</span><span class="p">(</span><span class="n">fd_keys</span><span class="p">,</span> <span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">,</span> <span class="n">reverse_encoder_inputs</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">feed_previous_prob_</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">encoder_inputs_</span><span class="p">,</span> <span class="n">encoder_input_lengths_</span>  <span class="o">=</span> <span class="n">format_batch</span><span class="p">(</span><span class="n">s_batch</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">reverse_encoder_inputs</span><span class="p">:</span>
        <span class="n">encoder_inputs_</span><span class="p">,</span> <span class="n">encoder_input_lengths_</span> <span class="o">=</span> <span class="n">format_batch</span><span class="p">([</span><span class="n">sequence</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">s_batch</span><span class="p">])</span>
    <span class="n">dec_seq_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">encoder_input_lengths_</span><span class="p">)</span><span class="o">+</span><span class="n">additional_decode_steps</span>
    <span class="c1"># enforce max length to equal the generated data (enc length + some margin of error)</span>
    <span class="n">decoder_targets_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">format_batch</span><span class="p">([</span><span class="n">sequence</span> <span class="o">+</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">t_batch</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">dec_seq_length</span><span class="p">)</span>
    <span class="n">decoder_inputs_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">format_batch</span><span class="p">([[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">t_batch</span><span class="p">],</span> <span class="n">max_length</span><span class="o">=</span><span class="n">dec_seq_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="n">fd_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">encoder_inputs_</span><span class="p">,</span>
        <span class="n">fd_keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="n">encoder_input_lengths_</span><span class="p">,</span>
        <span class="n">fd_keys</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span> <span class="n">decoder_inputs_</span><span class="p">,</span>
        <span class="n">fd_keys</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="n">decoder_targets_</span><span class="p">,</span>
        <span class="n">fd_keys</span><span class="p">[</span><span class="mi">4</span><span class="p">]:</span> <span class="n">feed_previous_prob_</span>
    <span class="p">}</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-the-model">Training the model<a class="anchor-link" href="#Training-the-model">&#194;&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># After how many sequences do we update the weights?</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span> <span class="c1"># Tensorboard stuff</span>
<span class="n">train_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_train</span><span class="p">)</span>
<span class="n">total_batches</span> <span class="o">=</span> <span class="n">train_length</span><span class="o">/</span><span class="n">batch_size</span> 
<span class="n">samples_in_final</span> <span class="o">=</span> <span class="n">train_length</span><span class="o">%</span><span class="k">batch_size</span> # number of samples in final batch

<span class="k">print</span> <span class="s2">&quot;there will be {} batches and {} samples in the final batch&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">total_batches</span><span class="p">,</span> <span class="n">samples_in_final</span><span class="p">)</span>
<span class="n">fd_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">encoder_inputs_length</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">decoder_targets</span><span class="p">,</span> <span class="n">feed_previous_prob</span><span class="p">]</span>
<span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training...&#39;</span><span class="p">)</span>
<span class="c1">#with tf.Session(config=tf.ConfigProto(</span>
<span class="c1">#  intra_op_parallelism_threads=NUM_CORES)) as sess:</span>
<span class="k">print</span> <span class="n">make_feed_dict</span><span class="p">(</span><span class="n">fd_keys</span><span class="p">,</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>

<span class="k">def</span> <span class="nf">save_metadata</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">get_fp_prob</span><span class="p">(</span><span class="n">feed_previous_prob</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">anneal_fp</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="c1"># This implements the growing/decaying feed previous prob</span>
    <span class="k">if</span> <span class="n">anneal_fp</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="n">epochs</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">i</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">feed_previous_prob</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>there will be 3370 batches and 92 samples in the final batch
Training...
{&lt;tf.Tensor &#39;encoder_inputs/encoder_inputs:0&#39; shape=(?, ?) dtype=int32&gt;: array([[2, 4],
       [3, 4],
       [3, 5]], dtype=int32), &lt;tf.Tensor &#39;encoder_inputs/encoder_inputs_length:0&#39; shape=(?,) dtype=int32&gt;: [3, 3], &lt;tf.Tensor &#39;feed_previous_prob:0&#39; shape=() dtype=float32&gt;: 1, &lt;tf.Tensor &#39;decoder_inputs/decoder_inputs:0&#39; shape=(?, ?) dtype=int32&gt;: array([[1, 1],
       [2, 4],
       [3, 4],
       [0, 0],
       [0, 0],
       [0, 0]], dtype=int32), &lt;tf.Tensor &#39;decoder_targets/decoder_targets:0&#39; shape=(?, ?) dtype=int32&gt;: array([[2, 4],
       [3, 4],
       [3, 5],
       [1, 1],
       [0, 0],
       [0, 0]], dtype=int32)}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.contrib.tensorboard.plugins</span> <span class="kn">import</span> <span class="n">projector</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">format_idx</span><span class="p">,</span> <span class="n">ids_to_phrases</span><span class="p">,</span> <span class="n">save_obj</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span><span class="n">log_device_placement</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">allow_soft_placement</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Initializing the variables</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    <span class="c1"># Many tensorboard things</span>
    <span class="n">train_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="o">+</span><span class="s1">&#39;/train&#39;</span><span class="p">,</span>
                                        <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span>
                                        <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
    <span class="c1"># This is for saving word embeddings</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">projector</span><span class="o">.</span><span class="n">ProjectorConfig</span><span class="p">()</span>
    <span class="n">embedding_enc</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
    <span class="n">embedding_enc</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">source_embeddings</span><span class="o">.</span><span class="n">name</span>
    <span class="c1"># Link this tensor to its metadata file (e.g. labels).</span>
    <span class="n">meta_s_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;metadata_s.tsv&#39;</span><span class="p">)</span>
    <span class="n">save_metadata</span><span class="p">(</span><span class="n">metadata_s</span><span class="p">,</span> <span class="n">meta_s_filename</span><span class="p">)</span>
    <span class="n">embedding_enc</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="n">meta_s_filename</span>

    <span class="n">embedding_dec</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
    <span class="n">embedding_dec</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">target_embeddings</span><span class="o">.</span><span class="n">name</span>
    <span class="c1"># Link this tensor to its metadata file (e.g. labels).</span>
    <span class="n">meta_t_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s1">&#39;metadata_t.tsv&#39;</span><span class="p">)</span>
    <span class="n">save_metadata</span><span class="p">(</span><span class="n">metadata_t</span><span class="p">,</span> <span class="n">meta_t_filename</span><span class="p">)</span>
    <span class="n">embedding_dec</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="n">meta_t_filename</span>

    <span class="c1"># Saves a configuration file that TensorBoard will read during startup.</span>
    <span class="n">projector</span><span class="o">.</span><span class="n">visualize_embeddings</span><span class="p">(</span><span class="n">summary_writer</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
    <span class="c1"># Training cycle</span>
    <span class="c1"># call the generator for fp_probs</span>
    <span class="n">feed_previous_prob</span> <span class="o">=</span> <span class="n">get_fp_prob</span><span class="p">(</span><span class="n">feed_previous_probability</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">anneal_fp</span><span class="o">=</span><span class="n">anneal_feed_previous</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">batch_n</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">ti</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="k">print</span> <span class="s2">&quot;training has begun...&quot;</span>
        <span class="n">epoch_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">fp_prob</span> <span class="o">=</span> <span class="n">feed_previous_prob</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;fp_prob = {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fp_prob</span><span class="p">))</span>
            <span class="n">ti</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">20</span>==0:
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">+</span><span class="s2">&quot;/model.ckpt&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span> <span class="ow">in</span> <span class="n">batch_source_target</span><span class="p">(</span><span class="n">s_train</span><span class="p">,</span>
                                                        <span class="n">t_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">feed_dict</span> <span class="o">=</span> <span class="n">make_feed_dict</span><span class="p">(</span><span class="n">fd_keys</span><span class="p">,</span><span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">,</span>
                                <span class="n">reverse_encoder_inputs</span><span class="o">=</span><span class="n">reverse_encoder_inputs</span><span class="p">,</span>
                                <span class="n">feed_previous_prob_</span><span class="o">=</span> <span class="n">fp_prob</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">train_op</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="p">)</span>
                <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">batch_n</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">batch_n</span><span class="o">%</span><span class="k">200</span>) == 0:
                    <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;epoch {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;batch {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_n</span><span class="o">-</span><span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">total_batches</span><span class="p">))</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;loss: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">)))</span>
                    <span class="k">print</span> <span class="s2">&quot;**********************************************&quot;</span><span class="o">*</span><span class="mi">5</span>
                    <span class="k">print</span> <span class="s2">&quot;$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$&quot;</span><span class="o">*</span><span class="mi">5</span>
                    <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;epoch {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
                    <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;batch {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_n</span><span class="o">-</span><span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">total_batches</span><span class="p">))</span>
                    <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;loss: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">)))</span>
                    <span class="n">summary_</span><span class="p">,</span> <span class="n">predict_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">merged</span><span class="p">,</span> <span class="n">decoder_prediction</span><span class="p">],</span> <span class="n">feed_dict</span><span class="p">)</span>
                    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary_</span><span class="p">,</span> <span class="n">batch_n</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="n">rand_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">batch_size</span><span class="o">-</span><span class="mi">10</span><span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">act</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feed_dict</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                                                 <span class="n">feed_dict</span><span class="p">[</span><span class="n">decoder_targets</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                                                 <span class="n">predict_</span><span class="o">.</span><span class="n">T</span><span class="p">)[</span><span class="n">rand_sample</span><span class="p">:</span><span class="n">rand_sample</span><span class="o">+</span><span class="mi">2</span><span class="p">]:</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;  sample {}:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;    input     : {} </span><span class="se">\n</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                         <span class="n">format_idx</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">id2word_s</span><span class="p">)))</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;    actual     : {} </span><span class="se">\n</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                         <span class="n">format_idx</span><span class="p">(</span><span class="n">act</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;    predicted     : {} </span><span class="se">\n</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                         <span class="n">format_idx</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;  sample {}:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
                        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;    input     : {} </span><span class="se">\n</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                         <span class="n">format_idx</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">id2word_s</span><span class="p">)))</span>
                        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;    actual     : {} </span><span class="se">\n</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                         <span class="n">format_idx</span><span class="p">(</span><span class="n">act</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;    predicted     : {} </span><span class="se">\n</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                         <span class="n">format_idx</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                        <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>
                <span class="n">batch_n</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Epoch {} took {} seconds to complete.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">ti</span><span class="p">))</span>
            <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;Epoch {} took {} seconds to complete, with average loss of {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span>
                                                    <span class="p">,</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">ti</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)))</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Epoch {} took {} seconds to complete, with average loss of {}.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span>
                                                    <span class="p">,</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">ti</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)))</span>
            <span class="n">save_obj</span><span class="p">(</span><span class="n">loss_list</span><span class="p">,</span> <span class="n">prepend</span><span class="o">+</span><span class="s2">&quot;loss_track&quot;</span><span class="p">)</span>
            <span class="n">actuals</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">epoch</span><span class="o">%</span><span class="k">5</span>==0:
                <span class="k">for</span> <span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span> <span class="ow">in</span> <span class="n">batch_source_target</span><span class="p">(</span><span class="n">s_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                    <span class="n">feed_dict</span> <span class="o">=</span> <span class="n">make_feed_dict</span><span class="p">(</span><span class="n">fd_keys</span><span class="p">,</span> <span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">,</span>
                                                    <span class="n">reverse_encoder_inputs</span><span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                                                    <span class="n">feed_previous_prob_</span><span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">predict_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">decoder_prediction</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">)</span>
                    <span class="k">for</span> <span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feed_dict</span><span class="p">[</span><span class="n">decoder_targets</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">predict_</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
                        <span class="n">actuals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">act</span><span class="p">)</span>
                        <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
                <span class="n">save_obj</span><span class="p">([</span><span class="n">actuals</span><span class="p">,</span> <span class="n">predictions</span><span class="p">],</span> <span class="n">prepend</span><span class="o">+</span><span class="s2">&quot;predictions{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
                <span class="k">print</span> <span class="s2">&quot;Made {} predictions.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">actuals</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">+</span><span class="s2">&quot;/model.ckpt&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
                <span class="k">break</span>
        <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;Training is complete&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Training is complete&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
        <span class="k">print</span> <span class="s1">&#39;training interrupted&#39;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>training has begun...
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 0
loss: 9.6329460144
  sample 1:
    input     : [15600, 23190, 2, 8372, 16407, 1] 
 ? mention &lt;UNK&gt; en pourquoi 
    actual     : [16104, 2420, 9653, 15886, 3969, 18840, 1, 1] 
 why am i mentioning this ? 
    predicted     : [1, 1, 1, 1, 1, 1396, 12702] 
 
  sample 2:
    input     : [2, 3782, 8004, 10817, 13299, 2, 2, 17773, 1] 
 &lt;UNK&gt; kevin mcgee frank leblanc &lt;UNK&gt; &lt;UNK&gt; ian 
    actual     : [16751, 2, 2, 2345, 14197, 12966, 11812, 2, 12086, 11859, 2, 4701, 2, 2, 2, 1, 1] 
 ian &lt;UNK&gt; &lt;UNK&gt; leblanc frank mcgee kevin &lt;UNK&gt; mary beth &lt;UNK&gt; paul &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
    predicted     : [1, 1, 1, 1, 1396, 1, 1396, 12702, 10657, 10657, 3789, 17517] 
 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 200
loss: 6.41302394867
  sample 1:
    input     : [10597, 10371, 8384, 18642, 8056, 7567, 8384, 22664, 20704, 10769, 8050, 17283, 8372, 21230, 10138, 1] 
 percussions des et piano du lectrique et acoustique guitare la de outre en joue je 
    actual     : [9653, 3071, 16806, 2912, 1405, 10855, 6588, 1, 1] 
 i play and really love it now 
    predicted     : [5916, 16806, 16806, 16806, 16806, 16806, 16806, 16806, 16806, 1, 1, 1, 1, 1] 
 the and and and and and and and and 
  sample 2:
    input     : [15736, 4356, 13687, 11408, 12851, 15224, 16480, 22570, 2, 24046, 11434, 271, 10769, 2467, 11408, 23508, 16480, 15224, 1] 
 particulier talent un d&amp;apos dot tre  pas &lt;UNK&gt; s&amp;apos ne confiance la inspirer d&amp;apos mme  tre 
    actual     : [2194, 9289, 2524, 15603, 3926, 10853, 6585, 14733, 2483, 7745, 12705, 13878, 1, 1] 
 being able to inspire confidence is not like having a particular talent 
    predicted     : [9653, 2, 2, 2524, 5916, 2, 2524, 2, 2, 1, 1, 1, 1, 1] 
 i &lt;UNK&gt; &lt;UNK&gt; to the &lt;UNK&gt; to &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 400
loss: 6.27553844452
  sample 1:
    input     : [277, 19175, 8050, 2, 15916, 16480, 22570, 4761, 14726, 4913, 34, 10769, 9317, 1] 
 alimentation l&amp;apos de &lt;UNK&gt; une  pas chappe &amp;quot n chine la mais 
    actual     : [15723, 7109, 10864, 125, 10853, 3062, 3806, 7745, 18886, 17345, 2, 1, 1] 
 however food in china is also experiencing a degree of &lt;UNK&gt; 
    predicted     : [5916, 10853, 5916, 5916, 5916, 2524, 5916, 1, 1, 1, 1] 
 the is the the the to the 
  sample 2:
    input     : [9358, 2, 2, 8050, 20475, 16989, 14837, 6541, 15392, 8050, 14322, 1] 
 inc &lt;UNK&gt; &lt;UNK&gt; de employs anciens certains visant remise de dcret 
    actual     : [2417, 2095, 5125, 17345, 2, 2, 4943, 1, 1] 
 certain former employees of &lt;UNK&gt; &lt;UNK&gt; inc 
    predicted     : [2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 600
loss: 6.23351955414
  sample 1:
    input     : [2, 8056, 22534, 7495, 10401, 12655, 1333, 10977, 23549, 10765, 18404, 8050, 7498, 8019, 11768, 16089, 1] 
 &lt;UNK&gt; du passagers les par utilis abondamment est sentier le compagnie de beaucoup alors aurez vous 
    actual     : [12682, 7970, 8505, 19923, 5916, 3736, 7418, 2593, 5916, 6301, 2, 4403, 1, 1] 
 two hundred metres below the summit you pass the upper &lt;UNK&gt; terminal 
    predicted     : [5916, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 1, 1, 1] 
 the the the the the the the the the 
  sample 2:
    input     : [6744, 10426, 10977, 7197, 5102, 24006, 8056, 13771, 10769, 1] 
 annule prsentement est guay yves syndic du licence la 
    actual     : [5916, 3263, 17345, 891, 16981, 2981, 10853, 3205, 12121, 1, 1] 
 the licence of trustee yves guay is currently cancelled 
    predicted     : [5916, 5916, 5916, 5916, 5916, 1, 1, 1] 
 the the the the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 800
loss: 6.20162582397
  sample 1:
    input     : [10416, 19175, 2, 5788, 10401, 10016, 8384, 22627, 1] 
 existence l&amp;apos &lt;UNK&gt; exemple par watts et jennings 
    actual     : [12332, 16806, 11701, 1048, 231, 1843, 5916, 16077, 17345, 7745, 1, 1] 
 jennings and watts for example note the presence of a 
    predicted     : [2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [11633, 10765, 24389, 12964, 3212, 20260, 8050, 11806, 14377, 8050, 1796, 6455, 6604, 3184, 7122, 9174, 1] 
 quartier le dans biens aux dommages de ou blesss de tat fait avait n&amp;apos information aucune 
    actual     : [17391, 969, 15785, 16182, 139, 17345, 13437, 17359, 5329, 2524, 5835, 10864, 5916, 1672, 1, 1] 
 there had been no reports of injuries or damages to property in the neighbourhood 
    predicted     : [5344, 18242, 17345, 5916, 5916, 5916, 5916, 5916, 5916, 1, 1, 1, 1, 1] 
 they are of the the the the the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 1000
loss: 5.85426330566
  sample 1:
    input     : [23689, 355, 8056, 19436, 10765, 1] 
 public dfenseur du bureau le 
    actual     : [5916, 12616, 3119, 8102, 5295, 1, 1] 
 the public defender &amp;aposs office 
    predicted     : [5916, 5916, 1, 1, 1, 1] 
 the the 
  sample 2:
    input     : [7308, 19175, 11434, 20548, 10659, 24774, 17578, 12708, 7495, 6940, 8384, 1] 
 taient l&amp;apos ne ils qu&amp;apos riches plus ocans les laisser et 
    actual     : [16806, 2524, 1324, 5916, 277, 11344, 658, 5728, 2887, 5332, 1, 1] 
 and to leave the oceans richer than we found them 
    predicted     : [16806, 16806, 16806, 16806, 16806, 16806, 16806, 1, 1, 1, 1] 
 and and and and and and and 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 1200
loss: 5.89581251144
  sample 1:
    input     : [19651, 14740, 18825, 2, 11434, 3488, 1] 
 vie leur nullement &lt;UNK&gt; ne elle 
    actual     : [10864, 16182, 6111, 6115, 16697, 2990, 19269, 9983, 1, 1] 
 in no way was she threatening their lives 
    predicted     : [10855, 10853, 2, 2, 2, 1, 1, 1] 
 it is &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [12101, 8384, 11289, 20614, 3902, 21327, 3184, 5480, 2, 13491, 10765, 2, 8384, 10201, 3177, 15916, 1] 
 pc et 360 xbox quelle importe n&amp;apos sur &lt;UNK&gt; jeu le &lt;UNK&gt; et compil fois une 
    actual     : [6543, 17232, 14733, 7745, 13467, 12560, 2524, 15197, 1, 1] 
 still seems like a big difference to me 
    predicted     : [7745, 16806, 16806, 16806, 16806, 16806, 16806, 2, 2, 2, 1, 1, 1] 
 a and and and and and and &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 1400
loss: 5.60226202011
  sample 1:
    input     : [24412, 13079, 24389, 24055, 10765, 2, 2, 8050, 22651, 7495, 19133, 13864, 19175, 8050, 17979, 8372, 2, 1] 
 tche sa dans chirurgien le &lt;UNK&gt; &lt;UNK&gt; de systmes les enregistre imagerie l&amp;apos de regard en &lt;UNK&gt; 
    actual     : [2, 10757, 7261, 2796, 5916, 2, 7797, 7765, 8336, 5916, 13790, 10864, 12314, 5202, 1, 1] 
 &lt;UNK&gt; against recorded imagery the &lt;UNK&gt; systems help guide the surgeon in critical work 
    predicted     : [2, 2, 2, 2, 5916, 5916, 5916, 5916, 2, 5916, 2, 1, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; the the the the &lt;UNK&gt; the &lt;UNK&gt; 
  sample 2:
    input     : [2, 21294, 3212, 24693, 831, 10371, 4446, 16898, 11434, 14113, 21471, 7495, 8384, 3284, 10765, 1] 
 &lt;UNK&gt; vastes aux secondaires causes des que sont ne naturelles catastrophes les et climat le 
    actual     : [1779, 8223, 16806, 1551, 1671, 3071, 9320, 7745, 5959, 13009, 10864, 2486, 6003, 1, 1] 
 climatic conditions and natural disasters play but a marginal part in mass starvation 
    predicted     : [5916, 16806, 16806, 16806, 16806, 5916, 5916, 5916, 5916, 5916, 1, 1, 1, 1] 
 the and and and and the the the the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 1600
loss: 5.48466682434
  sample 1:
    input     : [13845, 17342, 13687, 6585, 4590, 99, 9739, 1] 
 reu autre un dlivrer ensuite peut il 
    actual     : [5916, 3963, 6436, 5331, 7885, 5459, 9869, 1, 1] 
 the charity can then issue another receipt 
    predicted     : [10855, 10853, 2524, 2524, 2524, 1, 1, 1, 1] 
 it is to to to 
  sample 2:
    input     : [3785, 2, 8384, 2, 13848, 2, 3704, 1] 
 bailey &lt;UNK&gt; et &lt;UNK&gt; j.d. &lt;UNK&gt; peterson 
    actual     : [11583, 2, 4686, 2, 16806, 2, 11830, 1, 1] 
 peterson &lt;UNK&gt; j.d. &lt;UNK&gt; and &lt;UNK&gt; bailey 
    predicted     : [2, 2, 2, 2, 2, 2, 2, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 1800
loss: 5.63867330551
  sample 1:
    input     : [2, 7495, 4475, 4447, 7699, 8372, 2024, 19175, 8050, 22864, 1] 
 &lt;UNK&gt; les concerne qui ce en emballeur l&amp;apos de obligations 
    actual     : [13117, 17345, 5916, 4455, 2386, 17414, 2524, 2, 1, 1] 
 obligations of the packer with regard to &lt;UNK&gt; 
    predicted     : [5916, 5916, 5916, 5916, 5916, 1, 1, 1, 1] 
 the the the the the 
  sample 2:
    input     : [16580, 10769, 8050, 9726, 10769, 8050, 15362, 10769, 6018, 2, 17941, 1] 
 veille la de reconnaissance la de fatigue la encore &lt;UNK&gt; kennedy 
    actual     : [9892, 5331, 15497, 10855, 10082, 2386, 19970, 18019, 2, 16806, 2, 2, 1, 1] 
 he then took it across with lance corporal &lt;UNK&gt; and &lt;UNK&gt; &lt;UNK&gt; 
    predicted     : [2, 2, 5916, 5916, 5916, 5916, 5916, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; the the the the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 2000
loss: 5.24920988083
  sample 1:
    input     : [22570, 11567, 3184, 3693, 11772, 16977, 7495, 20039, 4446, 20917, 10977, 8173, 10769, 1] 
 pas avons n&amp;apos nous o endroits les pour que vrai est mto la 
    actual     : [17391, 10853, 2876, 7745, 2037, 8487, 17299, 1, 1] 
 there is always a backpack suitcase mood 
    predicted     : [5916, 10853, 10853, 10853, 6585, 2524, 2524, 1, 1, 1, 1, 1] 
 the is is is not to to 
  sample 2:
    input     : [5380, 16989, 3212, 10480, 3125, 7495, 5480, 14875, 4106, 1] 
 combattants anciens aux destines terres les sur loi  
    actual     : [12980, 6116, 7672, 2039, 2324, 1, 1] 
  war veterans allowance act 
    predicted     : [12980, 5916, 16543, 16543, 1, 1, 1, 1] 
  the information information 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 2200
loss: 5.21419382095
  sample 1:
    input     : [636, 8056, 12591, 10106, 13687, 16943, 12448, 11408, 12927, 10769, 2, 2, 9739, 1] 
 monde du record nouveau un tablissant arrive d&amp;apos ligne la &lt;UNK&gt; &lt;UNK&gt; il 
    actual     : [2425, 9892, 19947, 2589, 5916, 7118, 3636, 9892, 3364, 5916, 4907, 1258, 1, 1] 
 as he raced past the finish line he read the official time 
    predicted     : [9892, 2, 2, 5916, 5916, 5916, 7745, 7745, 7745, 1, 1, 1, 1, 1] 
 he &lt;UNK&gt; &lt;UNK&gt; the the the a a a 
  sample 2:
    input     : [2, 13081, 16480, 16157, 8384, 3525, 10765, 5480, 8243, 24046, 20548, 1] 
 &lt;UNK&gt; se  commencent et deal le sur entendent s&amp;apos ils 
    actual     : [5344, 10877, 5916, 11021, 16806, 4245, 7807, 1740, 5459, 1, 1] 
 they make the deal and start groping one another 
    predicted     : [5344, 5344, 5916, 16806, 16806, 16806, 16806, 1, 1, 1, 1, 1] 
 they they the and and and and 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 2400
loss: 5.32258033752
  sample 1:
    input     : [164, 2, 12504, 16130, 16867, 16193, 12927, 10769, 8050, 17569, 8050, 22389, 11238, 11111, 981, 12346, 1] 
 service &lt;UNK&gt; 2005 mai 30 centrale ligne la de renseignements de agent doughty m. avec entrevue 
    actual     : [11611, 17345, 15164, 7473, 7300, 3636, 15246, 15982, 13884, 11524, 13730, 5916, 11212, 496, 1, 1] 
 interview of m. doughty central line enquiry officer 30 may 2005 the insolvency service 
    predicted     : [6815, 2, 2386, 2, 2, 2, 2, 17345, 1, 1, 1, 1] 
 mr. &lt;UNK&gt; with &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; of 
  sample 2:
    input     : [19556, 10228, 15916, 6747, 4447, 15777, 22776, 8050, 1088, 15916, 24433, 2989, 13195, 7495, 1] 
 simule audience une comprend qui jours trois de initiation une reoivent membres nouveaux les 
    actual     : [10107, 12943, 10380, 12820, 7745, 11305, 7085, 19343, 17505, 7745, 18736, 15451, 1, 1] 
 new members went through a three-day orientation which included a mock hearing 
    predicted     : [5916, 5916, 18242, 7745, 7745, 7745, 7745, 7745, 7745, 1, 1, 1, 1] 
 the the are a a a a a a 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 2600
loss: 5.15843772888
  sample 1:
    input     : [12519, 8481, 13687, 981, 15623, 19175, 8050, 663, 7344, 7495, 14463, 10769, 2, 8050, 23696, 15224, 6707, 9739, 1] 
 courant fort un avec eau l&amp;apos de s victime les / la &lt;UNK&gt; de ncessaire tre pourrait il 
    actual     : [11524, 3537, 9731, 2524, 6973, 5937, 2033, 18946, 11727, 3856, 16367, 1, 1] 
 may be necessary to pluck victim s from fast flowing water 
    predicted     : [10855, 6436, 3537, 3537, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 1, 1, 1, 1] 
 it can be be the the the the the the the 
  sample 2:
    input     : [10773, 10765, 8384, 22326, 8371, 12153, 2, 10773, 14463, 663, 10765, 1] 
 lt le et din el nasser &lt;UNK&gt; lt / s le 
    actual     : [10935, 2524, 6904, 2386, 18194, 15982, 6875, 2, 12961, 1, 1] 
 left to baghdad with his officer &amp;quot &lt;UNK&gt; pilots 
    predicted     : [5916, 2, 2, 2, 16806, 16806, 16806, 16806, 1, 1, 1, 1] 
 the &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; and and and and 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 2800
loss: 4.97001934052
  sample 1:
    input     : [7319, 3874, 18575, 24458, 17998, 10765, 8384, 7319, 14707, 18575, 19409, 10401, 7624, 22776, 5369, 7260, 19757, 3488, 1] 
 heures quatre pendant matin samedi le et heures deux pendant semaine par soires trois portes ses ouvre elle 
    actual     : [10855, 3617, 6954, 7416, 7745, 17161, 1048, 1761, 2626, 16806, 15382, 11652, 1048, 12239, 2626, 1, 1] 
 it opens 3 evenings a week for 2 hours and saturday morning for 4 hours 
    predicted     : [9892, 6115, 18194, 18194, 16806, 16806, 16806, 16806, 16806, 16806, 1581, 1581, 1, 1, 1, 1] 
 he was his his and and and and and and years years 
  sample 2:
    input     : [12626, 2333, 21801, 2, 2333, 1] 
 saskatchewan regina museum &lt;UNK&gt; regina 
    actual     : [7254, 18359, 9854, 7254, 44, 1, 1] 
 regina firefighters museum regina saskatchewan 
    predicted     : [2, 2, 2, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 3000
loss: 4.8796954155
  sample 1:
    input     : [18631, 8372, 31, 3212, 9317, 14148, 3212, 5762, 7793, 22570, 16898, 11434, 4591, 16668, 7495, 1] 
 gnral en familles aux mais mres aux uniquement verses pas sont ne familiales allocations les 
    actual     : [854, 12949, 11786, 11849, 6585, 6889, 2524, 12569, 9320, 2524, 5808, 10864, 14566, 1, 1] 
 child benefits were paid not only to mothers but to families in general 
    predicted     : [5916, 18242, 18242, 6585, 6585, 2524, 2524, 2524, 1, 1, 1] 
 the are are not not to to to 
  sample 2:
    input     : [1136, 19450, 570, 18166, 18713, 8321, 7495, 19450, 570, 13007, 8056, 2946, 7495, 1] 
 retenus t ont projets cinq suivantes les t ont jury du dcisions les 
    actual     : [5916, 1368, 14246, 5916, 8857, 5089, 4742, 3471, 11786, 15085, 1, 1] 
 the jury reached the following decisions five projects were selected 
    predicted     : [5916, 11786, 11786, 11786, 11786, 11786, 11786, 11786, 11786, 1, 1, 1] 
 the were were were were were were were were 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 1
batch 3200
loss: 4.80035686493
  sample 1:
    input     : [7803, 16480, 3266, 8056, 1984, 6739, 8050, 21923, 10769, 8050, 1796, 4128, 9610, 10371, 13845, 21560, 11567, 3693, 1] 
 bruxelles  myanmar du responsables hauts de prsence la de tat faisant messages des reu galement avons nous 
    actual     : [5728, 3062, 5745, 11048, 6742, 7745, 3460, 9290, 13508, 10853, 10864, 8394, 1, 1] 
 we also received notification that a high-ranking burmese delegation is in brussels 
    predicted     : [5728, 3062, 3062, 5916, 5916, 5916, 17345, 5916, 17345, 5916, 1, 1, 1, 1] 
 we also also the the the of the of the 
  sample 2:
    input     : [20726, 8384, 7871, 11408, 18042, 21698, 1] 
 assistance et indices d&amp;apos programme  
    actual     : [9502, 4627, 16248, 17567, 1, 1] 
  informant leads program 
    predicted     : [9502, 5916, 16806, 16806, 1, 1, 1] 
  the and and 
Epoch 1 took 1508.81985998 seconds to complete, with average loss of 5.63855409622.
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 30
loss: 4.64336156845
  sample 1:
    input     : [769, 6964, 10765, 23514, 20548, 8384, 8269, 452, 16480, 22580, 24046, 8050, 16157, 10058, 7495, 15261, 8372, 1] 
 allemand berger le choisissent ils et ide cette  intresser s&amp;apos de commencent allemands les 1896 en 
    actual     : [10864, 9635, 5568, 18299, 6178, 10864, 5916, 12898, 16806, 18885, 5916, 6862, 18193, 10608, 1, 1] 
 in 1896 germany became interested in the idea and chose the german shepherd dog 
    predicted     : [10864, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 16806, 16806, 1, 1, 1, 1, 1] 
 in the the the the the the the the and and 
  sample 2:
    input     : [2, 2, 4023, 13157, 21171, 11626, 2, 8148, 6576, 9166, 8262, 8148, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &amp;amp allen beyond and &lt;UNK&gt; the for agenda global the 
    actual     : [5916, 6227, 9025, 1048, 5916, 11109, 16806, 7861, 1560, 2, 1690, 3451, 1, 1] 
 the global agenda for the 1990s and beyond st &lt;UNK&gt; nsw australia 
    predicted     : [5916, 5916, 17345, 5916, 5916, 2, 2, 2, 2, 1, 1, 1, 1] 
 the the of the the &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 230
loss: 4.51583099365
  sample 1:
    input     : [10670, 2, 14726, 21721, 14981, 11801, 10923, 2, 8148, 14726, 2, 13373, 16218, 1] 
 vol. &lt;UNK&gt; &amp;quot diversity species of value &lt;UNK&gt; the &amp;quot &lt;UNK&gt; t. 12 
    actual     : [11773, 2568, 2, 6875, 5916, 344, 14579, 17345, 7699, 11870, 6875, 2, 177, 1, 1] 
 12 t. &lt;UNK&gt; &amp;quot the hidden value of species diversity &amp;quot &lt;UNK&gt; vol 
    predicted     : [2, 2, 2, 2, 2, 6875, 2, 6875, 2, 1, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &amp;quot &lt;UNK&gt; &amp;quot &lt;UNK&gt; 
  sample 2:
    input     : [2, 11626, 127, 2108, 9741, 392, 19712, 11626, 16980, 2, 8148, 11801, 8517, 13264, 1] 
 &lt;UNK&gt; and development brain in role its and interaction &lt;UNK&gt; the of characterization structural 
    actual     : [2, 5291, 7745, 8220, 9086, 2, 7689, 1, 1] 
 &lt;UNK&gt; lindsay a mcmaster university &lt;UNK&gt; alba 
    predicted     : [2, 17345, 17345, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1] 
 &lt;UNK&gt; of of &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 430
loss: 4.50381135941
  sample 1:
    input     : [3235, 7142, 15916, 2, 24447, 16480, 6777, 8372, 12384, 11797, 19175, 3866, 13842, 2, 4119, 19175, 8372, 1] 
 histoire longue une &lt;UNK&gt; dossiers  arrire en regarde on l&amp;apos lorsque 2010 &lt;UNK&gt; anne l&amp;apos en 
    actual     : [10864, 5916, 16866, 6629, 4101, 17207, 1740, 19100, 13507, 2428, 2, 1626, 7745, 3637, 7683, 1, 1] 
 in the jubilee year 2010 when one looks back at &lt;UNK&gt; records a considerable history 
    predicted     : [10864, 5916, 5916, 2, 2, 2, 2, 10864, 7745, 10864, 7745, 1, 1, 1, 1, 1] 
 in the the &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; in a in a 
  sample 2:
    input     : [1662, 6118, 10371, 3520, 24684, 7260, 16480, 8384, 20618, 7015, 19075, 1] 
 1990 annes des zombies entreprises ses  et japon au pensez 
    actual     : [11714, 5306, 16806, 2831, 940, 11011, 17345, 5916, 5193, 6875, 2033, 1, 1] 
 think japan and its corporate zombies of the 1990 &amp;quot s 
    predicted     : [2428, 5916, 16806, 16806, 16806, 16806, 10864, 10864, 1, 1, 1, 1] 
 at the and and and and in in 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 630
loss: 4.43147754669
  sample 1:
    input     : [3147, 10371, 16480, 9487, 4512, 13081, 10090, 2524, 14893, 18166, 10371, 12879, 14726, 1724, 21137, 1] 
 difficults des  frquemment heurtent se exigences ces informatiques projets des chelle &amp;quot l a 
    actual     : [17338, 5916, 13524, 17345, 10855, 3471, 7067, 16516, 9639, 11336, 3645, 10757, 9654, 1, 1] 
 on the scale of it projects these requirements frequently run up against obstacles 
    predicted     : [5916, 5916, 17345, 17345, 7067, 2524, 1, 1, 1, 1, 1] 
 the the of of these to 
  sample 2:
    input     : [10175, 21095, 18870, 5480, 21491, 17782, 10371, 570, 12570, 7495, 4446, 17511, 11613, 452, 1] 
 biologiques ressources leurs sur souverains droits des ont tats les que raffirme convention cette 
    actual     : [5916, 16763, 2, 6742, 2742, 5842, 6106, 10217, 15302, 19269, 12581, 2725, 1, 1] 
 the convention &lt;UNK&gt; that states have sovereign rights over their biological resources 
    predicted     : [5916, 8696, 6742, 6742, 5916, 5916, 17345, 5916, 1, 1, 1, 1, 1] 
 the department that that the the of the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 830
loss: 4.44540548325
  sample 1:
    input     : [24458, 8056, 7319, 3874, 16480, 10947, 20375, 8384, 18635, 15777, 3874, 2, 848, 19357, 11567, 8372, 3693, 1] 
 matin du heures quatre  &amp;apos jusqu et durant jours quatre &lt;UNK&gt; sans discut avons en nous 
    actual     : [1048, 10, 15432, 5728, 17347, 16806, 17763, 5332, 1133, 183, 10, 10864, 5916, 11652, 1, 1] 
 for four days we discussed and debated them constantly until four in the morning 
    predicted     : [5728, 2, 2, 2, 2, 2, 16806, 16806, 16806, 16806, 15432, 1, 1, 1, 1] 
 we &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; and and and and days 
  sample 2:
    input     : [10115, 24834, 8050, 8384, 2, 8050, 13441, 8372, 15013, 5222, 15664, 21137, 2215, 7699, 1] 
 humaines vies de et &lt;UNK&gt; de termes en normment cot dj a conflit ce 
    actual     : [15446, 7745, 14538, 6827, 980, 15785, 11849, 10864, 9983, 16806, 11905, 1048, 3969, 8376, 1, 1] 
 already a tremendous price has been paid in lives and treasure for this conflict 
    predicted     : [3969, 980, 980, 15785, 2, 2, 2, 2, 2, 1, 1, 1, 1] 
 this has has been &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 1030
loss: 4.07556915283
  sample 1:
    input     : [15254, 14740, 24644, 11806, 12076, 10371, 20114, 19853, 19175, 1] 
 rmunration leur rduisent ou femmes des professionnel avancement l&amp;apos 
    actual     : [11382, 19354, 1048, 11596, 16244, 5192, 1, 1] 
 canadian centre for policy alternatives 1991 
    predicted     : [18982, 18982, 17359, 17359, 17359, 1, 1, 1, 1] 
 women women or or or 
  sample 2:
    input     : [15115, 7495, 20039, 21496, 13687, 4329, 24981, 10371, 5064, 7495, 2, 1] 
 voyageurs les pour danger un prsentent parois des dplacements les &lt;UNK&gt; 
    actual     : [2, 5916, 12774, 17345, 5916, 12862, 9108, 7745, 13446, 2524, 1384, 1, 1] 
 &lt;UNK&gt; the movements of the walls constitute a danger to passengers 
    predicted     : [2, 5916, 5916, 5916, 1048, 1048, 1, 1, 1, 1, 1] 
 &lt;UNK&gt; the the the for for 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 1230
loss: 4.07160377502
  sample 1:
    input     : [2, 2, 2, 16858, 1843, 167, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; luis rapporteur juge 
    actual     : [14637, 15958, 3558, 7115, 2, 2, 1, 1] 
 reporting judge luis gonzalo &lt;UNK&gt; &lt;UNK&gt; 
    predicted     : [5743, 5743, 2, 2, 2, 2, 1, 1] 
 rapporteur rapporteur &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [7774, 452, 24389, 2, 570, 3693, 4447, 8384, 7451, 8056, 2, 7495, 2416, 4447, 4419, 16898, 7699, 1] 
 crise cette dans &lt;UNK&gt; ont nous qui et pouvoir du &lt;UNK&gt; les tenaient qui eux sont ce 
    actual     : [10855, 6115, 5344, 19357, 3668, 15302, 10855, 16806, 15400, 3646, 3582, 10855, 1, 1] 
 it was they who presided over it and got us into it 
    predicted     : [5916, 19357, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 5916, 1, 1, 1, 1, 1] 
 the who the the the the the the the the the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 1430
loss: 4.00367259979
  sample 1:
    input     : [2, 11500, 23554, 663, 2, 13070, 10854, 1] 
 &lt;UNK&gt; dublin gate s &lt;UNK&gt; st brasserie 
    actual     : [7960, 6599, 8102, 15255, 12929, 18401, 2, 1, 1] 
 st. james &amp;aposs gate brewery dublin &lt;UNK&gt; 
    predicted     : [7960, 2, 2, 2, 2, 2, 1, 1] 
 st. &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [7774, 452, 5480, 12693, 6979, 16480, 20739, 10977, 24046, 18253, 260, 19175, 1] 
 crise cette sur reprises plusieurs  exprime est s&amp;apos europenne union l&amp;apos 
    actual     : [5916, 907, 822, 980, 11809, 2831, 3901, 17338, 3969, 16428, 17338, 15859, 7234, 1, 1] 
 the european union has voiced its opinion on this crisis on several occasions 
    predicted     : [5916, 907, 822, 980, 10853, 10864, 17338, 3969, 1, 1, 1, 1] 
 the european union has is in on this 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 1630
loss: 3.85105156898
  sample 1:
    input     : [17335, 7495, 3447, 22570, 14882, 11434, 11797, 17238, 7699, 10401, 1] 
 apparences les sauver pas souhaite ne on processus ce par 
    actual     : [10441, 8199, 16806, 11425, 5842, 5916, 11828, 2524, 6709, 1379, 3969, 9278, 1, 1] 
 aboriginal culture and spirituality have the potential to directly address this need 
    predicted     : [6742, 3969, 10853, 10853, 6585, 6585, 1, 1, 1, 1] 
 that this is is not not 
  sample 2:
    input     : [2, 8050, 15286, 13687, 5480, 2, 13687, 23237, 11408, 2, 22776, 7260, 16480, 7343, 9739, 17454, 10769, 16480, 1] 
 &lt;UNK&gt; de rouleau un sur &lt;UNK&gt; un crire d&amp;apos &lt;UNK&gt; trois ses  demande il fte la  
    actual     : [2428, 5916, 9623, 9892, 796, 18194, 10793, 2, 2524, 6473, 7745, 2, 17338, 7745, 18774, 1, 1] 
 at the party he asked his three &lt;UNK&gt; to write a &lt;UNK&gt; on a scroll 
    predicted     : [9892, 5916, 9892, 9892, 2, 7745, 7745, 7745, 7745, 2, 2, 2, 1, 1, 1] 
 he the he he &lt;UNK&gt; a a a a &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 1830
loss: 3.74873399734
  sample 1:
    input     : [6684, 6622, 7495, 10401, 10009, 6684, 8050, 2938, 19175, 8050, 11757, 2, 16761, 8057, 4106, 1] 
 calgary irsc les par financ calgary de universit l&amp;apos de chercheur &lt;UNK&gt; brent dr  
    actual     : [12980, 10106, 13520, 2, 2, 15447, 18946, 5916, 9086, 17345, 8629, 8629, 1, 1] 
  dr. brent &lt;UNK&gt; &lt;UNK&gt; researcher from the university of calgary calgary 
    predicted     : [12980, 10106, 6815, 2, 2, 17345, 17345, 17345, 17345, 17345, 1, 1, 1] 
  dr. mr. &lt;UNK&gt; &lt;UNK&gt; of of of of of 
  sample 2:
    input     : [13671, 4447, 7699, 10100, 2, 184, 19175, 8050, 15490, 4405, 13687, 7, 16220, 8, 1] 
 suit qui ce nonce &lt;UNK&gt; affaire l&amp;apos de tir extrait un &amp;#93 14 &amp;#91 
    actual     : [27, 11775, 26, 2423, 15996, 18946, 5916, 2, 17104, 2742, 5916, 8857, 1, 1] 
 &amp;#91 14 &amp;#93 an excerpt from the &lt;UNK&gt; case states the following 
    predicted     : [27, 27, 26, 5916, 5916, 5916, 5916, 5916, 5916, 1, 1, 1, 1] 
 &amp;#91 &amp;#91 &amp;#93 the the the the the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 2030
loss: 3.66009807587
  sample 1:
    input     : [6711, 10593, 5629, 9317, 1] 
 reviendrai y j&amp;apos mais 
    actual     : [9320, 9653, 3342, 11925, 13507, 2524, 6742, 1, 1] 
 but i &amp;aposll get back to that 
    predicted     : [9320, 9653, 9653, 1, 1, 1] 
 but i i 
  sample 2:
    input     : [7789, 6707, 21490, 3857, 4446, 388, 23041, 7495, 13496, 20914, 8372, 17331, 12769, 3693, 1] 
 avoir pourrait cela tout que accidentelles incidences les contre garde en mettre voudrions nous 
    actual     : [5728, 15161, 14733, 2524, 10203, 10757, 13693, 15841, 17345, 17536, 3969, 1, 1] 
 we would like to warn against accidental ramifications of all this 
    predicted     : [5728, 19610, 2524, 2524, 2524, 10864, 10864, 1, 1, 1, 1, 1] 
 we will to to to in in 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 2230
loss: 3.71924161911
  sample 1:
    input     : [6417, 2524, 8050, 21557, 11404, 7495, 20039, 20917, 17712, 10977, 21490, 1] 
 collectivits ces de hommes jeunes les pour vrai particulirement est cela 
    actual     : [5916, 3772, 18982, 5842, 2692, 18745, 2386, 19061, 13641, 11331, 16806, 1472, 1, 1] 
 the young women have more problems with abuse rejection pregnancies and abortion 
    predicted     : [3969, 10853, 10853, 1048, 1048, 1048, 1048, 1, 1, 1, 1] 
 this is is for for for for 
  sample 2:
    input     : [3479, 8050, 4446, 17578, 3628, 2, 3693, 3693, 9317, 1] 
 ridicule de que plus toutefois &lt;UNK&gt; nous nous mais 
    actual     : [9320, 5728, 18242, 17348, 17582, 658, 18234, 1, 1] 
 but we are inviting worse than ridicule 
    predicted     : [9320, 5728, 5728, 5728, 2692, 2692, 1, 1, 1] 
 but we we we more more 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 2430
loss: 3.4669175148
  sample 1:
    input     : [14726, 19947, 2, 17785, 8384, 17052, 20273, 16480, 11923, 1] 
 &amp;quot : &lt;UNK&gt; alan et richards catherine  flicitations 
    actual     : [1170, 2524, 4848, 4563, 16806, 16781, 14680, 3616, 6875, 1, 1] 
 congratulations to catherine richards and alan storey : &amp;quot 
    predicted     : [1170, 3556, 3556, 16806, 16806, 6875, 6875, 6875, 1, 1] 
 congratulations by by and and &amp;quot &amp;quot &amp;quot 
  sample 2:
    input     : [13263, 19175, 8384, 410, 10765, 8484, 8050, 8384, 19276, 1] 
 esprit l&amp;apos et corps le rajeunir de et dtendez-vous 
    actual     : [1214, 16806, 6394, 8241, 13851, 16806, 10549, 1, 1] 
 relax and rejuvenate both body and mind 
    predicted     : [2, 16806, 16806, 16806, 16806, 16806, 1, 1, 1] 
 &lt;UNK&gt; and and and and and 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 2630
loss: 3.57489991188
  sample 1:
    input     : [12948, 11239, 12946, 4981, 19087, 18094, 1] 
 158 - 156 lectronique commerce v 
    actual     : [17765, 5463, 860, 2, 15555, 9069, 1, 1] 
 v electronic commerce &lt;UNK&gt; - 158 
    predicted     : [2, 2, 15555, 15555, 15555, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; - - - 
  sample 2:
    input     : [4768, 18376, 7701, 22275, 3924, 3693, 10083, 8384, 3155, 22919, 2731, 7495, 1] 
 amis devenus rapidement trs sommes nous moi-mme et auxiliaires administrateurs autres les 
    actual     : [17338, 15219, 2, 16551, 9653, 702, 7745, 2, 16806, 19695, 1, 1] 
 on my &lt;UNK&gt; birthday i boarded a &lt;UNK&gt; and english 
    predicted     : [5916, 19962, 16806, 16806, 16806, 16806, 16806, 16806, 7497, 1, 1, 1, 1, 1] 
 the other and and and and and and very 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 2830
loss: 3.38567376137
  sample 1:
    input     : [17961, 10769, 24389, 22605, 981, 2, 16480, 2732, 16480, 2, 24046, 20548, 1] 
 jeep la dans moi avec &lt;UNK&gt;  jouer  &lt;UNK&gt; s&amp;apos ils 
    actual     : [5344, 11786, 2483, 13331, 12807, 15079, 16806, 10560, 2386, 15197, 1175, 5916, 17344, 1, 1] 
 they were having fun playing hide and seek with me inside the jeep 
    predicted     : [5344, 19610, 2524, 2524, 2524, 2524, 2386, 10864, 10864, 1, 1, 1, 1] 
 they will to to to to with in in 
  sample 2:
    input     : [22194, 8372, 14320, 16480, 4541, 16419, 8050, 8384, 12667, 16419, 8050, 14227, 1] 
 considration en prendre  blesses personnes de et tues personnes de nombre 
    actual     : [15365, 6629, 19426, 17345, 2400, 16806, 7772, 18242, 7194, 3556, 18936, 13719, 1, 1] 
 each year thousands of pedestrians and cyclists are struck by motor vehicles 
    predicted     : [2973, 17345, 1028, 1028, 16806, 16806, 16806, 1, 1, 1, 1] 
 number of people people and and and 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 3030
loss: 3.26138830185
  sample 1:
    input     : [7616, 12557, 15916, 20039, 9941, 13081, 16681, 8050, 4894, 10371, 14726, 1329, 8903, 19175, 1] 
 spciale soire une pour rassemblent se fans de milliers des &amp;quot rassemble vnement l&amp;apos 
    actual     : [5916, 7863, 192, 8018, 17345, 19426, 17345, 13214, 14355, 1048, 2423, 7805, 9119, 1, 1] 
 the event brings &amp;apos of thousands of fans gather for an evening special 
    predicted     : [5916, 5916, 17345, 17345, 17345, 2, 5842, 1048, 1048, 1048, 1, 1, 1, 1] 
 the the of of of &lt;UNK&gt; have for for for 
  sample 2:
    input     : [4064, 8050, 7569, 10371, 16553, 1] 
 montral de leveurs des association 
    actual     : [5916, 15413, 9024, 6742, 11744, 6436, 19159, 1, 1] 
 the free encyclopedia that anyone can edit 
    predicted     : [11382, 17345, 1, 1, 1] 
 canadian of 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 2
batch 3230
loss: 3.25892329216
  sample 1:
    input     : [3279, 22275, 22570, 9317, 23096, 18185, 1] 
 agrable trs pas mais fonctionnel hotel 
    actual     : [5916, 19887, 6800, 6115, 2692, 8033, 658, 9653, 6115, 7924, 1, 1] 
 the continental breakfast was more substantial than i was expecting 
    predicted     : [5916, 18048, 6115, 9320, 9320, 9320, 1, 1, 1] 
 the hotel was but but but 
  sample 2:
    input     : [19947, 7626, 8372, 14256, 8050, 22570, 23422, 7495, 22402, 23539, 8056, 19574, 3212, 5762, 14256, 1] 
 : avance en vente de pas matchs les avant stade du caisses aux uniquement vente 
    actual     : [16182, 2, 10853, 17938, 5049, 18242, 6889, 19465, 2428, 5916, 833, 12211, 10324, 5916, 15751, 1, 1] 
 no &lt;UNK&gt; is organised tickets are only available at the stadium gates before the games 
    predicted     : [2, 6585, 5916, 5916, 10324, 10324, 10324, 10324, 1, 1, 1, 3616] 
 &lt;UNK&gt; not the the before before before before 
Epoch 2 took 1510.6219101 seconds to complete, with average loss of 3.93072223663.
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 60
loss: 3.33603739738
  sample 1:
    input     : [14726, 10354, 14726, 21152, 1] 
 &amp;quot rserv &amp;quot lire 
    actual     : [8723, 3364, 6875, 13976, 6875, 1, 1] 
 e read &amp;quot reserved &amp;quot 
    predicted     : [3364, 3364, 1, 1, 1] 
 read read 
  sample 2:
    input     : [17392, 9358, 24259, 4023, 17750, 1760, 24748, 9496, 2, 9741, 1305, 2, 13354, 13492, 1] 
 1968 inc sons &amp;amp wiley john york new &lt;UNK&gt; in process &lt;UNK&gt; to introduction 
    actual     : [2, 12009, 11373, 16798, 2, 2033, 7270, 1568, 2, 18344, 1, 1] 
 &lt;UNK&gt; jr dewar r &lt;UNK&gt; s kirkland sa &lt;UNK&gt; pj 
    predicted     : [2, 2, 2, 2, 2, 2, 2, 2] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 260
loss: 2.89447116852
  sample 1:
    input     : [14348, 11797, 19175, 4446, 7699, 5480, 22391, 15224, 11408, 21327, 9739, 9317, 1] 
 prdit on l&amp;apos que ce sur clair tre d&amp;apos importe il mais 
    actual     : [9320, 1740, 4402, 3537, 8093, 14814, 17640, 1740, 10853, 12046, 1, 1] 
 but one should be clear about what one is forecasting 
    predicted     : [9320, 10855, 10853, 3537, 3537, 17338, 1, 1, 1] 
 but it is be be on 
  sample 2:
    input     : [990, 6142, 10977, 24046, 12864, 8050, 22259, 8050, 12323, 13687, 1] 
 ainsi exprim est s&amp;apos spectacles de lieu de propritaire un 
    actual     : [2425, 1740, 15042, 4234, 10716, 1, 1] 
 as one venue owner said 
    predicted     : [7745, 17345, 17345, 10853, 10853, 1, 1] 
 a of of is is 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 460
loss: 3.03338217735
  sample 1:
    input     : [5753, 8050, 24801, 8056, 10503, 16216, 16480, 14998, 10977, 2, 11239, 2, 11143, 1] 
 toulon de centre du km 10  situ est &lt;UNK&gt; - &lt;UNK&gt; my 
    actual     : [15219, 2, 15555, 2, 10853, 2596, 10940, 11771, 13098, 18946, 5916, 19354, 17345, 18501, 1, 1] 
 my &lt;UNK&gt; - &lt;UNK&gt; is situated just 10 km from the centre of toulon 
    predicted     : [15219, 2, 2, 2, 10853, 10853, 7745, 5916, 5916, 1, 1, 1, 1] 
 my &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; is is a the the 
  sample 2:
    input     : [19633, 6455, 10765, 9739, 1] 
 volontairement fait le il 
    actual     : [9892, 4797, 1563, 12283, 1, 1] 
 he does so voluntarily 
    predicted     : [9892, 10853, 1, 1, 1, 1] 
 he is 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 660
loss: 3.06585025787
  sample 1:
    input     : [4981, 18086, 1] 
 lectronique authentification 
    actual     : [5463, 12164, 1, 1] 
 electronic authentication 
    predicted     : [12164, 12164, 1, 1] 
 authentication authentication 
  sample 2:
    input     : [277, 19175, 8050, 522, 1] 
 alimentation l&amp;apos de troubles 
    actual     : [8537, 11272, 1, 1] 
 eating disorders 
    predicted     : [1175, 17345, 11272, 1, 1] 
 inside of disorders 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 860
loss: 2.96549010277
  sample 1:
    input     : [2, 2122, 7008, 9361, 8050, 23000, 16085, 19175, 23175, 8384, 16987, 1] 
 &lt;UNK&gt; not am i de virtuel univers l&amp;apos achetez et dcouvrez 
    actual     : [6308, 16806, 14868, 9653, 2420, 6585, 2, 8102, 14936, 9613, 1, 1] 
 discover and buy i am not &lt;UNK&gt; &amp;aposs virtual merchandise 
    predicted     : [6308, 16806, 16806, 16806, 16806, 5916, 1, 1, 1, 1, 1, 1] 
 discover and and and and the 
  sample 2:
    input     : [24061, 8050, 7958, 10769, 21019, 7011, 13687, 4303, 23231, 13687, 11408, 10806, 9445, 24046, 9739, 1] 
 lisbonne de stratgie la aprs an un dcevant rsultat un d&amp;apos l agit s&amp;apos il 
    actual     : [3969, 10853, 7745, 18405, 11831, 10864, 5916, 11716, 6629, 7459, 5916, 13202, 18336, 6115, 19395, 1, 1] 
 this is a disappointing performance in the first year since the lisbon strategy was agreed 
    predicted     : [3969, 10853, 7745, 7745, 7745, 7745, 17345, 17345, 1, 1, 1, 1, 1] 
 this is a a a a of of 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 1060
loss: 2.82977581024
  sample 1:
    input     : [11514, 10371, 7940, 8050, 24447, 7495, 20337, 1645, 8384, 20207, 4124, 10371, 16193, 10769, 11514, 10371, 7940, 1] 
 fournisseurs des rendement de dossiers les priodiquement rvise et conserve achats des centrale la fournisseurs des rendement 
    actual     : [18516, 11831, 7300, 9291, 19216, 16806, 11465, 14809, 18516, 11831, 18661, 1, 1] 
 vendor performance central purchasing maintains and reviews periodically vendor performance files 
    predicted     : [12980, 2524, 17345, 5916, 16806, 16806, 16806, 1, 1, 1, 1, 1, 1, 1] 
  to of the and and and 
  sample 2:
    input     : [7428, 8372, 23508, 12723, 16898, 5939, 8050, 11718, 7495, 4446, 9236, 4106, 1] 
 hiver en mme courants sont soleil de coups les que sachez  
    actual     : [12980, 2, 10853, 13182, 10090, 10864, 5916, 1512, 1, 1] 
  &lt;UNK&gt; is common even in the winter 
    predicted     : [12980, 17640, 5916, 5916, 2, 18242, 10864, 10864, 10864, 1, 1, 1] 
  what the the &lt;UNK&gt; are in in in 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 1260
loss: 2.72495222092
  sample 1:
    input     : [2, 4447, 21769, 7495, 2, 19292, 10769, 24389, 18941, 2, 13488, 16007, 10371, 1] 
 &lt;UNK&gt; qui rsidents les &lt;UNK&gt; foule la dans dlibrment &lt;UNK&gt; militaires vhicules des 
    actual     : [143, 13719, 11786, 15388, 13453, 3582, 2402, 16806, 12183, 15302, 19920, 614, 3902, 1, 1] 
 military vehicles were driving deliberately into crowds and running over protesting camp residents 
    predicted     : [2, 17345, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1] 
 &lt;UNK&gt; of &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [17261, 10371, 24653, 11408, 7385, 8050, 22570, 6604, 10593, 3184, 9739, 21137, 1] 
 risques des valuation d&amp;apos mthode de pas avait y n&amp;apos il a 
    actual     : [7745, 17391, 6115, 16182, 2614, 17345, 15022, 15177, 1, 1] 
 a there was no method of risk assessment 
    predicted     : [17391, 17391, 16182, 16182, 16182, 1, 1, 1, 1, 1] 
 there there no no no 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 1460
loss: 2.76869463921
  sample 1:
    input     : [15316, 24801, 13687, 11806, 23679, 15916, 16606, 8050, 22259, 13687, 7833, 15916, 24389, 22570, 1541, 11434, 16527, 10769, 1] 
 commercial centre un ou institution une travail de lieu un rsidence une dans pas survient ne chute la 
    actual     : [17294, 13847, 1, 1] 
 table 3c 
    predicted     : [5916, 6585, 6585, 7745, 7745, 7745, 7745, 7745, 7745, 17359, 7745, 7275, 1, 1] 
 the not not a a a a a a or a business 
  sample 2:
    input     : [1870, 15224, 20039, 17515, 3467, 16592, 7308, 2, 7495, 1] 
 stockes tre pour sales fortement donc taient &lt;UNK&gt; les 
    actual     : [2, 11786, 179, 13500, 6388, 1048, 7409, 1, 1] 
 &lt;UNK&gt; were therefore often salted for storage 
    predicted     : [2, 2, 11786, 2, 2524, 2524, 3537, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; were &lt;UNK&gt; to to be 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 1660
loss: 2.68897652626
  sample 1:
    input     : [18253, 659, 662, 8050, 19685, 10371, 24726, 20039, 2266, 8050, 11214, 21137, 13610, 8266, 10769, 8050, 7774, 10769, 1] 
 europenne conomique gouvernance de plans des laborer pour prtexte de servi a euro zone la de crise la 
    actual     : [5916, 3879, 16428, 6115, 8380, 2425, 7745, 17865, 2524, 12253, 16677, 1048, 907, 8508, 12683, 1, 1] 
 the euro crisis was used as a pretext to forge plans for european economic governance 
    predicted     : [5916, 16428, 16428, 16428, 5916, 5916, 5916, 5916, 1048, 1048, 907, 907, 1, 1, 1] 
 the crisis crisis crisis the the the the for for european european 
  sample 2:
    input     : [7319, 3874, 8050, 24489, 8372, 19816, 10371, 14757, 19175, 16480, 9107, 21137, 3635, 2, 956, 1] 
 heures quatre de moins en dinosaures des installation l&amp;apos  procd a international &lt;UNK&gt; research 
    actual     : [2923, 15947, 11354, 16926, 5916, 286, 10864, 4688, 658, 10, 2626, 1, 1] 
 research casting international installed the dinosaurs in less than four hours 
    predicted     : [11354, 11354, 2, 10853, 5916, 5916, 17345, 1, 1, 1, 1] 
 international international &lt;UNK&gt; is the the of 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 1860
loss: 2.70044326782
  sample 1:
    input     : [20050, 8384, 902, 6239, 10769, 4446, 6589, 10800, 10371, 19525, 7324, 20548, 1] 
 medicare et sociale scurit la que tels programmes des dmanteler esprent ils 
    actual     : [5344, 4413, 2524, 2, 10917, 1544, 2425, 6444, 6002, 16806, 17352, 1, 1] 
 they hope to &lt;UNK&gt; programs such as social security and medicare 
    predicted     : [5344, 19610, 2524, 2524, 2524, 2524, 16806, 16806, 16806, 6444, 16806, 1, 1] 
 they will to to to to and and and social and 
  sample 2:
    input     : [5814, 14464, 20678, 16351, 16898, 1709, 7495, 8718, 20039, 15104, 7495, 10401, 2, 2, 7495, 1] 
 etc. chantage sduction multiples sont enfants les approcher pour internautes les par &lt;UNK&gt; &lt;UNK&gt; les 
    actual     : [1686, 18742, 5842, 18264, 12724, 1048, 3176, 12529, 5470, 2, 4520, 1, 1] 
 internet users have various strategies for approaching children seduction &lt;UNK&gt; etc 
    predicted     : [5916, 2, 18242, 5916, 12529, 12529, 18242, 12529, 1, 1, 1, 1, 1, 1] 
 the &lt;UNK&gt; are the children children are children 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 2060
loss: 2.59378218651
  sample 1:
    input     : [23575, 10765, 8384, 2, 10765, 19549, 19175, 22963, 19904, 8050, 839, 7015, 21212, 24866, 13687, 23306, 9739, 1] 
 hertfordshire le et &lt;UNK&gt; le essex l&amp;apos entre londres de nord au foss norme un existe il 
    actual     : [17391, 10853, 7745, 2753, 13305, 2524, 5916, 9870, 17345, 15307, 10864, 2337, 2, 16806, 3393, 1, 1] 
 there is a huge gap to the north of london in essex &lt;UNK&gt; and hertfordshire 
    predicted     : [17391, 10853, 7745, 7745, 10864, 10864, 10864, 5916, 16806, 16806, 16806, 16806, 1, 1, 1, 1] 
 there is a a in in in the and and and and 
  sample 2:
    input     : [2928, 4287, 11408, 4826, 15916, 11391, 9987, 2, 13990, 3488, 15398, 8372, 1] 
 australienne affaires d&amp;apos banque une corp finance &lt;UNK&gt; acquiert elle 1985 en 
    actual     : [10864, 14852, 10855, 19470, 2, 11603, 5604, 2423, 16446, 15017, 5349, 1, 1] 
 in 1985 it acquired &lt;UNK&gt; finance corp an australian merchant bank 
    predicted     : [10864, 14852, 2, 2, 2, 2, 5349, 5349, 5349, 1, 1, 1, 1, 1] 
 in 1985 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; bank bank bank 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 2260
loss: 2.57702755928
  sample 1:
    input     : [14442, 10977, 4673, 13687, 13073, 10897, 8050, 23372, 7545, 2, 8056, 13787, 8476, 1] 
 abordable est logement un si dterminer de moyen comme &lt;UNK&gt; du cot ratio 
    actual     : [14779, 6311, 6036, 18732, 2307, 2425, 7745, 9113, 17345, 3078, 1, 1] 
 shelter cost / income ratios as a measure of affordability 
    predicted     : [6311, 6311, 17345, 17345, 2524, 2524, 10853, 10853, 1, 1, 1, 1] 
 cost cost of of to to is is 
  sample 2:
    input     : [12315, 1] 
 united 
    actual     : [4920, 1, 1] 
 qantas 
    predicted     : [19028, 1, 1] 
 united 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 2460
loss: 2.88930606842
  sample 1:
    input     : [15600, 2513, 15916, 10806, 22570, 7196, 3184, 1] 
 ? absurdit une l pas est-ce n&amp;apos 
    actual     : [10459, 8108, 6742, 2423, 7862, 18840, 1, 1] 
 isn &amp;apost that an absurdity ? 
    predicted     : [10853, 10855, 7745, 7745, 7745, 18840, 1, 1] 
 is it a a a ? 
  sample 2:
    input     : [24469, 7495, 6296, 1300, 13081, 24546, 2524, 8050, 3159, 17578, 7495, 1984, 7495, 19009, 15025, 1] 
 barreaux les derrire trouvent se violations ces de notoires plus les responsables les hui aujourd&amp;apos 
    actual     : [5916, 13081, 16514, 2, 17345, 10952, 10217, 18509, 8162, 6742, 17042, 18242, 6588, 10864, 977, 1, 1] 
 the most emblematic &lt;UNK&gt; of human rights violations during that period are now in prison 
    predicted     : [16449, 5916, 5916, 5916, 5916, 7067, 18242, 18242, 7067, 1, 1, 1, 1] 
 today the the the the these are are these 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 2660
loss: 2.64558029175
  sample 1:
    input     : [18750, 10769, 8050, 3333, 19175, 16480, 5946, 2529, 16480, 8366, 9566, 18750, 16480, 2, 8050, 10976, 1] 
 vapeur la de aide l&amp;apos  avancer faire  servant appareil vapeur  &lt;UNK&gt; de systme 
    actual     : [11374, 2, 4248, 2, 3091, 6742, 2, 7745, 15902, 1, 1] 
 stem &lt;UNK&gt; system &lt;UNK&gt; apparatus that &lt;UNK&gt; a submarine 
    predicted     : [2, 2, 2, 2524, 2524, 2524, 2524, 2524, 2524, 1, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; to to to to to to 
  sample 2:
    input     : [3177, 13550, 10769, 20039, 15864, 1485, 2, 10371, 4446, 6589, 17188, 10371, 1] 
 fois premire la pour apparaissent familiers &lt;UNK&gt; des que tels oiseaux des 
    actual     : [6544, 1544, 2425, 2, 18242, 15967, 1048, 5916, 11716, 1258, 5916, 11346, 1, 1] 
 birds such as &lt;UNK&gt; are appearing for the first time the anecdotes 
    predicted     : [5344, 17345, 18242, 2425, 18242, 5916, 5916, 1, 1, 1, 1, 1] 
 they of are as are the the 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 2860
loss: 2.40521907806
  sample 1:
    input     : [6123, 1] 
 ~ 
    actual     : [5728, 5842, 734, 17345, 10217, 1, 1] 
 we have lots of rights 
    predicted     : [2, 1, 1] 
 &lt;UNK&gt; 
  sample 2:
    input     : [8992, 13517, 7495, 20039, 164, 8050, 9604, 7495, 5480, 7766, 7359, 1] 
 externes frais les pour service de normes les sur politique b. 
    actual     : [14055, 11596, 17338, 496, 16313, 1048, 7053, 18014, 1, 1] 
 b- policy on service standards for external fees 
    predicted     : [3503, 11596, 17338, 496, 496, 1, 1, 1] 
 b. policy on service service 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 3060
loss: 2.57610416412
  sample 1:
    input     : [14707, 11806, 3566, 15916, 7083, 8050, 21034, 8050, 8064, 15916, 2654, 8372, 23306, 9739, 1] 
 deux ou roupie une gagner de faons de multitude une effet en existe il 
    actual     : [17391, 18242, 2027, 1883, 2524, 10877, 7745, 17190, 17359, 12682, 1, 1] 
 there are many ways to make a rupee or two 
    predicted     : [17391, 18242, 7745, 1883, 1883, 7745, 7745, 12682, 17359, 12682, 1, 1, 1] 
 there are a ways ways a a two or two 
  sample 2:
    input     : [5501, 8372, 14320, 8384, 2, 14779, 10977, 14666, 10003, 1] 
 charge en prendre et &lt;UNK&gt; informer est c&amp;apos agir 
    actual     : [12922, 8914, 17350, 358, 16806, 14500, 16274, 1, 1] 
 acting means informing educating and taking charge 
    predicted     : [10855, 10853, 2, 16806, 16806, 16806, 1, 1, 1] 
 it is &lt;UNK&gt; and and and 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 3
batch 3260
loss: 2.43847846985
  sample 1:
    input     : [9767, 8050, 2446, 7495, 1] 
 facto de mariages les 
    actual     : [5647, 14180, 2663, 1, 1] 
 de facto marriages 
    predicted     : [2, 17345, 1, 1, 1] 
 &lt;UNK&gt; of 
  sample 2:
    input     : [9310, 15014, 14550, 1] 
 sociaux stigmates  
    actual     : [19359, 6444, 11974, 1, 1] 
  social stigma 
    predicted     : [12980, 6444, 6444, 1, 1] 
  social social 
Epoch 3 took 1512.21572995 seconds to complete, with average loss of 2.80022144318.
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 90
loss: 2.38209486008
  sample 1:
    input     : [15738, 9578, 14726, 13635, 22529, 8056, 2678, 1] 
 rectifi quivalence &amp;quot d facteur du guide 
    actual     : [4986, 18789, 681, 8336, 1, 1] 
 pension adjustment reversal guide 
    predicted     : [5916, 17345, 17345, 1, 1, 1] 
 the of of 
  sample 2:
    input     : [2, 4873, 2, 15446, 2, 4873, 2, 15446, 20427, 10818, 21745, 6231, 10769, 1] 
 &lt;UNK&gt;  &lt;UNK&gt; jorge &lt;UNK&gt;  &lt;UNK&gt; jorge by mexicaine rvolution prochaine la 
    actual     : [10851, 8102, 3934, 6302, 3556, 16038, 2, 14216, 2, 16038, 2, 14216, 2, 1, 1] 
 mexico &amp;aposs next revolution by jorge &lt;UNK&gt;  &lt;UNK&gt; jorge &lt;UNK&gt;  &lt;UNK&gt; 
    predicted     : [5916, 3934, 8102, 3556, 3556, 2, 2, 2, 2, 2, 2, 2, 1, 1] 
 the next &amp;aposs by by &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 290
loss: 2.45282793045
  sample 1:
    input     : [11141, 10618, 1] 
 mr nicaragua 
    actual     : [13518, 1, 1] 
 nicaragua 
    predicted     : [6815, 6815, 1, 1, 1] 
 mr. mr. 
  sample 2:
    input     : [19947, 2993, 13081, 3596, 1112, 1054, 8384, 2, 2, 20306, 6527, 1] 
 : raliser se rves vos puissent et &lt;UNK&gt; &lt;UNK&gt; chance bonne 
    actual     : [12855, 2326, 2, 2, 17338, 18684, 7333, 7760, 3616, 1, 1] 
 good luck &lt;UNK&gt; &lt;UNK&gt; on fulfilling your dream : 
    predicted     : [12855, 2326, 2, 2, 16806, 16806, 7333, 7333, 3616, 1, 1, 1] 
 good luck &lt;UNK&gt; &lt;UNK&gt; and and your your : 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 490
loss: 2.53444576263
  sample 1:
    input     : [16641, 11965, 8050, 14362, 570, 6970, 14707, 7495, 16521, 19175, 24389, 1] 
 adquate manire de ragi ont parties deux les ensemble l&amp;apos dans 
    actual     : [3556, 16806, 15384, 8241, 2358, 5842, 5591, 10864, 2423, 5633, 5529, 1, 1] 
 by and large both sides have responded in an adequate manner 
    predicted     : [8241, 8241, 2343, 2343, 2343, 2524, 1, 1, 1, 1] 
 both both parties parties parties to 
  sample 2:
    input     : [24592, 14039, 19175, 16480, 6539, 16592, 6707, 8384, 5789, 19175, 489, 12686, 10371, 18142, 10769, 1] 
 pondrale insuffisance l&amp;apos  contribuer donc pourrait et apptit l&amp;apos diminue cigarettes des nicotine la 
    actual     : [17928, 18946, 18127, 9573, 1922, 14992, 16806, 11524, 4930, 2524, 2, 1, 1] 
 nicotine from cigarette smoking suppresses appetite and may contribute to &lt;UNK&gt; 
    predicted     : [5916, 5916, 17345, 17345, 16806, 16806, 16806, 2524, 2524, 1, 1, 1, 1, 1] 
 the the of of and and and to to 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 690
loss: 2.42535042763
  sample 1:
    input     : [2, 24753, 948, 13272, 23815, 7495, 20039, 17650, 19175, 1] 
 &lt;UNK&gt; adrian sign climatiques changements les pour ambassadeur l&amp;apos 
    actual     : [15265, 2, 1, 1] 
 adrian &lt;UNK&gt; 
    predicted     : [9896, 2, 1048, 1, 1, 1, 1] 
 signed &lt;UNK&gt; for 
  sample 2:
    input     : [2853, 8050, 14227, 8056, 23034, 16216, 8050, 14190, 8050, 17641, 15916, 3628, 19461, 11797, 1] 
 retraites de nombre du % 10 de prs de hausse une toutefois observe on 
    actual     : [15723, 17391, 6115, 2423, 6648, 10864, 9791, 17345, 14596, 11771, 13674, 1, 1] 
 however there was an increase in retirements of almost 10 % 
    predicted     : [15723, 5916, 10853, 10853, 17345, 17345, 17345, 17345, 17345, 17345, 1, 1, 1, 1] 
 however the is is of of of of of of 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 890
loss: 2.44032907486
  sample 1:
    input     : [15600, 11728, 10977, 20207, 8372, 8384, 11892, 24678, 8384, 8424, 10371, 8026, 17746, 10769, 13073, 5306, 17366, 16089, 1] 
 ? intacte est conserve en et congels lgumes et fruits des nutritive valeur la si parfois demandez-vous vous 
    actual     : [5640, 7418, 11979, 14814, 5916, 11724, 14579, 17345, 807, 17359, 18380, 6778, 16806, 2, 18840, 1, 1] 
 do you wonder about the nutritional value of canned or frozen fruits and &lt;UNK&gt; ? 
    predicted     : [7418, 7418, 7418, 5916, 5916, 5916, 16806, 16806, 16806, 16806, 16806, 16806, 1, 18840, 1, 1] 
 you you you the the the and and and and and and 
  sample 2:
    input     : [8981, 5370, 8050, 5480, 2, 11408, 14757, 1] 
 distances longues de sur &lt;UNK&gt; d&amp;apos installation 
    actual     : [2621, 17345, 7003, 2, 1, 1] 
 installations of long-distance &lt;UNK&gt; 
    predicted     : [2, 17345, 17345, 1, 1, 1, 1] 
 &lt;UNK&gt; of of 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 1090
loss: 2.47155308723
  sample 1:
    input     : [24702, 2, 1] 
 procdure &lt;UNK&gt; 
    actual     : [15828, 1, 1] 
 procedure 
    predicted     : [15828, 1, 1] 
 procedure 
  sample 2:
    input     : [15600, 14165, 23289, 10765, 2220, 22570, 5860, 3184, 16407, 16089, 15042, 1] 
 ? jacob beau le choisi pas a-t-elle n&amp;apos pourquoi vous selon 
    actual     : [263, 5640, 7418, 18003, 14814, 2, 11598, 2, 5916, 3934, 11029, 2, 18840, 1, 1] 
 how do you feel about &lt;UNK&gt; main &lt;UNK&gt; the next wwe &lt;UNK&gt; ? 
    predicted     : [1563, 7418, 10602, 8108, 16104, 5916, 5916, 5916, 18840, 18840, 1, 1] 
 so you don &amp;apost why the the the ? ? 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 1290
loss: 2.40734767914
  sample 1:
    input     : [15319, 2, 4559, 20815, 2, 22685, 17578, 12913, 15042, 1] 
 tait &lt;UNK&gt; mcdermott james &lt;UNK&gt; rcent plus son selon 
    actual     : [18194, 13081, 3392, 2, 6599, 14622, 151, 2, 2425, 1, 1] 
 his most recent &lt;UNK&gt; james mcdermott characterises &lt;UNK&gt; as 
    predicted     : [1048, 3392, 3392, 2, 2, 2, 2, 2, 1, 1, 1] 
 for recent recent &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [19389, 2, 14354, 23762, 10000, 1] 
 sar &lt;UNK&gt; fleming charlie adjuc 
    actual     : [18544, 15650, 4112, 11127, 18353, 14516, 1, 1] 
 capt. tammy newman editor flight comment 
    predicted     : [2, 2, 2, 2, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 1490
loss: 2.29975271225
  sample 1:
    input     : [1301, 20345, 3792, 11239, 10019, 8838, 2, 18185, 11218, 6462, 22922, 1] 
 clients commentaires 205 - suisse lucerne &lt;UNK&gt; hotel western best booking.com 
    actual     : [13279, 727, 15503, 18048, 2, 7948, 8184, 15555, 530, 2985, 11465, 1, 1] 
 booking.com best western hotel &lt;UNK&gt; lucerne switzerland - 205 guest reviews 
    predicted     : [13279, 727, 15503, 18048, 2, 7948, 15555, 15555, 2985, 2985, 11465, 1] 
 booking.com best western hotel &lt;UNK&gt; lucerne - - guest guest reviews 
  sample 2:
    input     : [19947, 2, 19175, 16480, 22534, 8050, 11604, 23480, 1] 
 : &lt;UNK&gt; l&amp;apos  passagers de millions neuf 
    actual     : [7677, 1699, 1384, 2428, 518, 11354, 12651, 3616, 1, 1] 
 nine million passengers at geneva international airport : 
    predicted     : [7677, 1699, 1699, 2, 1, 1, 1, 1] 
 nine million million &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 1690
loss: 2.33467078209
  sample 1:
    input     : [10341, 11408, 3084, 1] 
 armes d&amp;apos destruction 
    actual     : [9644, 17345, 16982, 1, 1] 
 destruction of weapons 
    predicted     : [9644, 17345, 16982, 1, 1] 
 destruction of weapons 
  sample 2:
    input     : [8436, 17578, 9030, 7005, 5629, 4446, 3393, 15916, 16480, 9428, 11123, 21490, 1] 
 tt plus faite ai j&amp;apos que observation une  ramne me cela 
    actual     : [3969, 192, 15197, 13507, 2524, 19017, 9653, 9044, 11679, 1, 1] 
 this brings me back to something i mentioned earlier 
    predicted     : [10855, 15197, 15197, 15197, 15197, 15197, 9653, 1, 1, 1] 
 it me me me me me i 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 1890
loss: 2.24105739594
  sample 1:
    input     : [24745, 13872, 11806, 13931, 2951, 8372, 9030, 24112, 10977, 23108, 452, 1] 
 nuit bleu ou noir tissu en faite traditionnellement est tenue cette 
    actual     : [5916, 3614, 10853, 15546, 11913, 17359, 19434, 15076, 1, 1] 
 the suit is traditionally black or midnight blue 
    predicted     : [3969, 10853, 10853, 8009, 11913, 11913, 11913, 11913, 11913, 1, 1] 
 this is is grey black black black black black 
  sample 2:
    input     : [7526, 2679, 7699, 8050, 19607, 8372, 16268, 11408, 20205, 15916, 7598, 21137, 10593, 9739, 1] 
 tableau sombre ce de dpit en esprer d&amp;apos raison une nanmoins a y il 
    actual     : [17391, 10853, 15723, 7745, 365, 17559, 10864, 5916, 2228, 16304, 1, 1] 
 there is however a silver lining in the dark clouds 
    predicted     : [17391, 8102, 7745, 7745, 7745, 17345, 17345, 17345, 1, 1, 1, 1, 1] 
 there &amp;aposs a a a of of of 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 2090
loss: 2.35487961769
  sample 1:
    input     : [12024, 9566, 19175, 20039, 22697, 8050, 927, 9583, 8697, 570, 3184, 13720, 2524, 1] 
 reproducteur appareil l&amp;apos pour toxicit de signe aucun rvl ont n&amp;apos tudes ces 
    actual     : [7067, 1400, 535, 16182, 6158, 17345, 6136, 15887, 1, 1] 
 these studies showed no evidence of reproductive toxicity 
    predicted     : [3969, 1400, 16182, 16182, 16182, 1048, 1048, 1, 1, 1, 1] 
 this studies no no no for for 
  sample 2:
    input     : [20002, 11790, 7015, 9452, 15916, 16898, 4473, 24961, 2524, 1] 
 palestinien peuple au insulte une sont absurdes interprtations ces 
    actual     : [7067, 10533, 12473, 18242, 2423, 5165, 2524, 5916, 5159, 1028, 1, 1] 
 these silly interpretations are an insult to the palestinian people 
    predicted     : [7067, 7067, 18242, 18242, 7745, 2524, 2524, 5159, 5159, 1, 1, 1] 
 these these are are a to to palestinian palestinian 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 2290
loss: 2.37934827805
  sample 1:
    input     : [10246, 2, 10401, 6559, 8384, 15218, 2, 15916, 21557, 3212, 9030, 22635, 10769, 1] 
 dallaire &lt;UNK&gt; par complexe et tabou &lt;UNK&gt; une hommes aux faite violence la 
    actual     : [2730, 3452, 17345, 7941, 19061, 19269, 8074, 16806, 12754, 3556, 2, 338, 1, 1] 
 male victims of elder abuse their experiences and needs by &lt;UNK&gt; pritchard 
    predicted     : [5916, 12350, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1] 
 the violence &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; 
  sample 2:
    input     : [9409, 5726, 16480, 21046, 5057, 10765, 2, 4952, 7495, 1] 
 h. 9  dimanche port le &lt;UNK&gt; navires les 
    actual     : [5916, 19115, 15922, 11508, 2428, 18433, 9511, 1, 1] 
 the ships depart sunday at 9 a.m. 
    predicted     : [5916, 2, 5916, 5916, 17338, 10715, 1, 1, 1, 1] 
 the &lt;UNK&gt; the the on 00 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 2490
loss: 2.22639584541
  sample 1:
    input     : [3455, 8557, 6555, 18323, 10765, 24389, 12927, 8372, 12049, 11154, 1] 
 commission document unique march le dans ligne en cratifs contenus 
    actual     : [6237, 10420, 6819, 10864, 5916, 13665, 6387, 10796, 7114, 1, 1] 
 creative content online in the single market commission document 
    predicted     : [5916, 2, 10864, 5916, 5916, 1, 1, 1, 1] 
 the &lt;UNK&gt; in the the 
  sample 2:
    input     : [11008, 8372, 886, 13079, 16480, 14726, 20375, 19659, 19175, 8050, 10480, 3212, 19095, 9739, 3100, 13079, 10401, 10217, 1] 
 1988 en mort sa  &amp;quot jusqu entreprise l&amp;apos de destines aux prside il femme sa par second 
    actual     : [14601, 3556, 18194, 17516, 9892, 16739, 5916, 2700, 183, 18194, 7179, 10864, 14859, 1, 1] 
 helped by his wife he oversaw the company until his death in 1988 
    predicted     : [2, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 10864, 10864, 1, 1, 1] 
 &lt;UNK&gt; his his his his his his his in in 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 2690
loss: 2.36338567734
  sample 1:
    input     : [9995, 8056, 20399, 4181, 9226, 1796, 11408, 10541, 11111, 19423, 18486, 2, 261, 1] 
 royaume-uni du office foreign adjoint tat d&amp;apos sous-secrtaire m. roger sir &lt;UNK&gt; . 
    actual     : [2, 19027, 1961, 15164, 18925, 1134, 17345, 9469, 13246, 5295, 17345, 19028, 17249, 1, 1] 
 &lt;UNK&gt; sir roger m. deputy under-secretary of state foreign office of united kingdom 
    predicted     : [2, 2, 19027, 1961, 15164, 1134, 17345, 17345, 13246, 19028, 19028, 17249, 1, 1, 1] 
 &lt;UNK&gt; &lt;UNK&gt; sir roger m. under-secretary of of foreign united united kingdom 
  sample 2:
    input     : [10371, 23087, 1834, 4138, 10371, 8304, 8384, 984, 1] 
 des chargs techniques services des adresses et noms 
    actual     : [13910, 16806, 8881, 17345, 3890, 13085, 571, 1, 1] 
 names and addresses of technical services responsible 
    predicted     : [13910, 16806, 16806, 3890, 13085, 13085, 1, 1] 
 names and and technical services services 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 2890
loss: 2.67484259605
  sample 1:
    input     : [20571, 8384, 17827, 570, 10452, 7495, 4446, 7699, 5480, 2084, 15916, 10401, 19994, 1] 
 appris et ressenti ont participants les que ce sur discussion une par continuez 
    actual     : [18272, 7745, 8142, 12952, 5916, 11588, 545, 1, 1] 
 creating a circle reinforces the group feeling 
    predicted     : [1847, 7745, 6468, 16806, 16806, 16806, 16806, 1, 1, 1] 
 take a discussion and and and and 
  sample 2:
    input     : [18422, 21606, 23897, 13687, 20039, 2062, 1] 
 edd durable dveloppement un pour ducation 
    actual     : [9925, 1048, 18219, 13374, 14780, 1, 1] 
 education for sustainable development esd 
    predicted     : [9925, 1048, 18219, 18219, 13374, 1, 1] 
 education for sustainable sustainable development 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 3090
loss: 2.42170858383
  sample 1:
    input     : [23913, 17121, 14130, 13687, 8372, 3195, 2, 6610, 981, 18380, 10765, 1] 
 entier muscle seul un en consiste &lt;UNK&gt; tendon avec filet le 
    actual     : [5916, 8358, 2386, 16869, 2, 10007, 17345, 7745, 13665, 17295, 14669, 1, 1] 
 the tenderloin with tendon &lt;UNK&gt; consists of a single intact muscle 
    predicted     : [5916, 8358, 16869, 16869, 5916, 7745, 7745, 7745, 14669, 14669, 14669, 1] 
 the tenderloin tendon tendon the a a a muscle muscle muscle 
  sample 2:
    input     : [6163, 11684, 21019, 16939, 15224, 4918, 2, 8056, 5557, 10765, 2, 1] 
 usage chaque aprs nettoy tre devra &lt;UNK&gt; du bout le &lt;UNK&gt; 
    actual     : [3969, 14769, 19777, 7418, 16134, 7333, 15117, 10338, 658, 13869, 5640, 1, 1] 
 this happens because you hear your voice differently than others do 
    predicted     : [2, 5916, 2, 17345, 3537, 3537, 3537, 5260, 5260, 5260, 1, 1, 1] 
 &lt;UNK&gt; the &lt;UNK&gt; of be be be after after after 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 4
batch 3290
loss: 2.36351394653
  sample 1:
    input     : [4195, 5554, 8705, 4959, 4195, 2, 23560, 1] 
 adresse avenue fielding 52 adresse &lt;UNK&gt; allison 
    actual     : [18032, 2, 1379, 15977, 4601, 17867, 1379, 1, 1] 
 allison &lt;UNK&gt; address 52 fielding avenue address 
    predicted     : [18032, 2, 1379, 2, 16752, 17867, 1379, 1, 1] 
 allison &lt;UNK&gt; address &lt;UNK&gt; district avenue address 
  sample 2:
    input     : [10888, 9325, 7937, 21768, 10401, 5670, 12938, 1] 
 national correspondant adensamer martin par prpar rsum 
    actual     : [6155, 13699, 3556, 18593, 11633, 14448, 19682, 1, 1] 
 abstract prepared by martin adensamer national correspondent 
    predicted     : [6155, 13699, 3556, 18593, 11633, 14448, 19682, 1, 1] 
 abstract prepared by martin adensamer national correspondent 
Epoch 4 took 1513.14871287 seconds to complete, with average loss of 2.4319331646.
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 5
batch 120
loss: 2.24811577797
  sample 1:
    input     : [19727, 8384, 17387, 18736, 8050, 8400, 10371, 16480, 4106, 1] 
 dtailles et gnrales synthse de fiches des   
    actual     : [12980, 14566, 16806, 2408, 4237, 1, 1] 
  general and detailed summaries 
    predicted     : [12980, 2, 2, 16806, 1, 1, 1] 
  &lt;UNK&gt; &lt;UNK&gt; and 
  sample 2:
    input     : [8213, 2, 14463, 14463, 3080, 1519, 14011, 2, 4687, 23179, 2, 20332, 2, 23179, 1] 
 pays &lt;UNK&gt; / / http web site &lt;UNK&gt; @ bridget &lt;UNK&gt; courriel &lt;UNK&gt; bridget 
    actual     : [4512, 2, 9778, 2, 4512, 15018, 2, 4707, 4613, 9627, 6036, 6036, 2, 778, 1, 1] 
 bridget &lt;UNK&gt; e-mail &lt;UNK&gt; bridget @ &lt;UNK&gt; web site http / / &lt;UNK&gt; country 
    predicted     : [4512, 2, 2, 2, 2, 6036, 2, 6036, 2, 6036, 2, 2] 
 bridget &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; &lt;UNK&gt; / &lt;UNK&gt; / &lt;UNK&gt; / &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 5
batch 320
loss: 2.1987323761
  sample 1:
    input     : [17578, 2, 13081, 11434, 21490, 2805, 1] 
 plus &lt;UNK&gt; se ne cela apparemment 
    actual     : [14315, 10855, 8219, 8108, 6632, 12454, 1, 1] 
 apparently it won &amp;apost happen again 
    predicted     : [14315, 3969, 11311, 6585, 16222, 2692, 1, 1, 1] 
 apparently this did not longer more 
  sample 2:
    input     : [5371, 16898, 2, 10371, 24775, 7495, 981, 1142, 20039, 18253, 13378, 10769, 10401, 16703, 23809, 7495, 1] 
 vains sont &lt;UNK&gt; des derniers les avec communiquer pour europenne population la par dploys efforts les 
    actual     : [16069, 19915, 3556, 5916, 907, 16792, 2524, 17323, 2386, 5916, 18953, 10835, 2, 7021, 2360, 1, 1] 
 efforts made by the european population to communicate with the few remaining &lt;UNK&gt; proved futile 
    predicted     : [16069, 16069, 16069, 5916, 5916, 5916, 5916, 2524, 5916, 5916, 2, 2, 1, 1, 1, 1] 
 efforts efforts efforts the the the the to the the &lt;UNK&gt; &lt;UNK&gt; 
**************************************************************************************************************************************************************************************************************************************
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
epoch 5
batch 520
loss: 2.01952528954
  sample 1:
    input     : [7615, 18988, 10371, 23974, 19175, 8050, 3949, 7015, 4750, 11408, 4138, 8050, 5304, 10769, 20039, 15147, 1] 
 unies nations des organisation l&amp;apos de sige au entretien d&amp;apos services de fourniture la pour contrat 
    actual     : [8290, 17025, 2428, 19028, 539, 303, 1, 1] 
 maintenance contract at united nations headquarters 
    predicted     : [1048, 1048, 5916, 5916, 1048, 5916, 600, 1048, 1, 1, 1] 
 for for the the for the organization for 
  sample 2:
    input     : [10211, 8384, 22452, 11408, 4718, 10371, 5179, 9726, 10769, 17035, 4106, 1] 
 4 et exportations d&amp;apos licences des mutuelle reconnaissance la appliquer  
    actual     : [12980, 18939, 19952, 4784, 2524, 19792, 16364, 16806, 1, 1] 
  apply mutual recognition to export authorisations and 
    predicted     : [12980, 2524, 5916, 17345, 17345, 17345, 12239, 12239, 1, 1] 
  to the of of of 4 4 
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="k">def</span> <span class="nf">test_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Test the saved model against the test dataset</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1">#raw_s_test = load_obj(&quot;DATA/source_test&quot;) # Data for benchmark model </span>
    <span class="c1">#raw_t_test = load_obj(&quot;DATA/target_test&quot;) # Data for benchmark model </span>
    <span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span><span class="n">log_device_placement</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                    <span class="n">allow_soft_placement</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="c1"># Load model</span>
        <span class="k">if</span> <span class="n">testing_only</span><span class="p">:</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">log_dir</span><span class="o">+</span><span class="s1">&#39;model.ckpt-40&#39;</span><span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
            <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">)</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">actuals</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="n">fd_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">decoder_targets</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">batch_n</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">print</span> <span class="s2">&quot;testing has begun...&quot;</span>
            <span class="k">for</span> <span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span> <span class="ow">in</span> <span class="n">batch_source_target</span><span class="p">(</span><span class="n">s_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                <span class="n">feed_dict</span> <span class="o">=</span> <span class="n">make_feed_dict</span><span class="p">(</span><span class="n">fd_keys</span><span class="p">,</span> <span class="n">s_batch</span><span class="p">,</span> <span class="n">t_batch</span><span class="p">,</span>
                                                <span class="n">reverse_encoder_inputs</span><span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                                                <span class="n">feed_previous_prob_</span><span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">predict_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">decoder_prediction</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">)</span>
                
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">act</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feed_dict</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                                                         <span class="n">feed_dict</span><span class="p">[</span><span class="n">decoder_targets</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                                                         <span class="n">predict_</span><span class="o">.</span><span class="n">T</span><span class="p">)):</span>
                    <span class="n">actuals</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">remove_EOS_PAD</span><span class="p">(</span><span class="n">act</span><span class="p">)])</span>
                    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">remove_EOS_PAD</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
                    <span class="k">print</span> <span class="s2">&quot;batch number: &quot;</span><span class="p">,</span> <span class="n">batch_n</span>
                    <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;    actual     : {} </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                     <span class="n">format_idx</span><span class="p">(</span><span class="n">act</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                    <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;    predicted     : {} </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                     <span class="n">format_idx</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;    actual     : {} </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                     <span class="n">format_idx</span><span class="p">(</span><span class="n">act</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">act</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;    predicted     : {} </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                     <span class="n">format_idx</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">ids_to_phrases</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">id2word_t</span><span class="p">)))</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span><span class="mi">3</span><span class="p">:</span>
                        <span class="k">break</span>

            <span class="n">batch_n</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="k">print</span> <span class="s1">&#39;testing interrupted&#39;</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd"># Get Tensors from loaded model</span>
<span class="sd">loaded_x = loaded_graph.get_tensor_by_name(&#39;x:0&#39;)</span>
<span class="sd">loaded_y = loaded_graph.get_tensor_by_name(&#39;y:0&#39;)</span>
<span class="sd">loaded_keep_prob = loaded_graph.get_tensor_by_name(&#39;keep_prob:0&#39;)</span>
<span class="sd">loaded_logits = loaded_graph.get_tensor_by_name(&#39;logits:0&#39;)</span>
<span class="sd">loaded_acc = loaded_graph.get_tensor_by_name(&#39;accuracy:0&#39;)</span>

<span class="sd"># Get accuracy in batches for memory limitations</span>
<span class="sd">test_batch_acc_total = 0</span>
<span class="sd">test_batch_count = 0</span>

<span class="sd">for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):</span>
<span class="sd">    test_batch_acc_total += sess.run(</span>
<span class="sd">        loaded_acc,</span>
<span class="sd">        feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})</span>
<span class="sd">    test_batch_count += 1</span>

<span class="sd">print(&#39;Testing Accuracy: {}\n&#39;.format(test_batch_acc_total/test_batch_count))</span>

<span class="sd"># Print Random Samples</span>
<span class="sd">random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))</span>
<span class="sd">random_test_predictions = sess.run(</span>
<span class="sd">    tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),</span>
<span class="sd">    feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})</span>
<span class="sd">helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">test_model</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NotFoundError</span>                             Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-24-a6fb770cd285&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     74</span> &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">     75</span> 
<span class="ansi-green-fg">---&gt; 76</span><span class="ansi-red-fg"> </span>test_model<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-24-a6fb770cd285&gt;</span> in <span class="ansi-cyan-fg">test_model</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     14</span>         <span class="ansi-green-fg">if</span> testing_only<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     15</span>             loader <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>train<span class="ansi-blue-fg">.</span>import_meta_graph<span class="ansi-blue-fg">(</span>log_dir<span class="ansi-blue-fg">+</span><span class="ansi-blue-fg">&#39;model.ckpt-40&#39;</span><span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">&#39;.meta&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 16</span><span class="ansi-red-fg">             </span>loader<span class="ansi-blue-fg">.</span>restore<span class="ansi-blue-fg">(</span>sess<span class="ansi-blue-fg">,</span> log_dir<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     17</span>         predictions<span class="ansi-blue-fg">,</span> actuals <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     18</span>         fd_keys <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>encoder_inputs<span class="ansi-blue-fg">,</span> decoder_inputs<span class="ansi-blue-fg">,</span> decoder_targets<span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc</span> in <span class="ansi-cyan-fg">restore</span><span class="ansi-blue-fg">(self, sess, save_path)</span>
<span class="ansi-green-intense-fg ansi-bold">   1455</span>     logging<span class="ansi-blue-fg">.</span>info<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Restoring parameters from %s&#34;</span><span class="ansi-blue-fg">,</span> save_path<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1456</span>     sess.run(self.saver_def.restore_op_name,
<span class="ansi-green-fg">-&gt; 1457</span><span class="ansi-red-fg">              {self.saver_def.filename_tensor_name: save_path})
</span><span class="ansi-green-intense-fg ansi-bold">   1458</span> 
<span class="ansi-green-intense-fg ansi-bold">   1459</span>   <span class="ansi-blue-fg">@</span>staticmethod

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(self, fetches, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">    776</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    777</span>       result = self._run(None, fetches, feed_dict, options_ptr,
<span class="ansi-green-fg">--&gt; 778</span><span class="ansi-red-fg">                          run_metadata_ptr)
</span><span class="ansi-green-intense-fg ansi-bold">    779</span>       <span class="ansi-green-fg">if</span> run_metadata<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    780</span>         proto_data <span class="ansi-blue-fg">=</span> tf_session<span class="ansi-blue-fg">.</span>TF_GetBuffer<span class="ansi-blue-fg">(</span>run_metadata_ptr<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc</span> in <span class="ansi-cyan-fg">_run</span><span class="ansi-blue-fg">(self, handle, fetches, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">    980</span>     <span class="ansi-green-fg">if</span> final_fetches <span class="ansi-green-fg">or</span> final_targets<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    981</span>       results = self._do_run(handle, final_targets, final_fetches,
<span class="ansi-green-fg">--&gt; 982</span><span class="ansi-red-fg">                              feed_dict_string, options, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">    983</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    984</span>       results <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc</span> in <span class="ansi-cyan-fg">_do_run</span><span class="ansi-blue-fg">(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">   1030</span>     <span class="ansi-green-fg">if</span> handle <span class="ansi-green-fg">is</span> None<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1031</span>       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
<span class="ansi-green-fg">-&gt; 1032</span><span class="ansi-red-fg">                            target_list, options, run_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">   1033</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1034</span>       return self._do_call(_prun_fn, self._session, handle, feed_dict,

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc</span> in <span class="ansi-cyan-fg">_do_call</span><span class="ansi-blue-fg">(self, fn, *args)</span>
<span class="ansi-green-intense-fg ansi-bold">   1050</span>         <span class="ansi-green-fg">except</span> KeyError<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1051</span>           <span class="ansi-green-fg">pass</span>
<span class="ansi-green-fg">-&gt; 1052</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">raise</span> type<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">(</span>node_def<span class="ansi-blue-fg">,</span> op<span class="ansi-blue-fg">,</span> message<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1053</span> 
<span class="ansi-green-intense-fg ansi-bold">   1054</span>   <span class="ansi-green-fg">def</span> _extend_graph<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">NotFoundError</span>: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for fp_06_data/nmt_8/
	 [[Node: save_39/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=&#34;/job:localhost/replica:0/task:0/cpu:0&#34;](_recv_save_39/Const_0, save_39/RestoreV2_12/tensor_names, save_39/RestoreV2_12/shape_and_slices)]]

Caused by op u&#39;save_39/RestoreV2_12&#39;, defined at:
  File &#34;/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py&#34;, line 174, in _run_module_as_main
    &#34;__main__&#34;, fname, loader, pkg_name)
  File &#34;/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py&#34;, line 72, in _run_code
    exec code in run_globals
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py&#34;, line 3, in &lt;module&gt;
    app.launch_new_instance()
  File &#34;/usr/local/lib/python2.7/site-packages/traitlets/config/application.py&#34;, line 658, in launch_instance
    app.start()
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py&#34;, line 474, in start
    ioloop.IOLoop.instance().start()
  File &#34;/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py&#34;, line 177, in start
    super(ZMQIOLoop, self).start()
  File &#34;/usr/local/lib/python2.7/site-packages/tornado/ioloop.py&#34;, line 887, in start
    handler_func(fd_obj, events)
  File &#34;/usr/local/lib/python2.7/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper
    return fn(*args, **kwargs)
  File &#34;/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py&#34;, line 440, in _handle_events
    self._handle_recv()
  File &#34;/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py&#34;, line 472, in _handle_recv
    self._run_callback(callback, msg)
  File &#34;/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py&#34;, line 414, in _run_callback
    callback(*args, **kwargs)
  File &#34;/usr/local/lib/python2.7/site-packages/tornado/stack_context.py&#34;, line 275, in null_wrapper
    return fn(*args, **kwargs)
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py&#34;, line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py&#34;, line 228, in dispatch_shell
    handler(stream, idents, msg)
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py&#34;, line 390, in execute_request
    user_expressions, allow_stdin)
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py&#34;, line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File &#34;/usr/local/lib/python2.7/site-packages/ipykernel/zmqshell.py&#34;, line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File &#34;/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py&#34;, line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File &#34;/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py&#34;, line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File &#34;/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py&#34;, line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-24-a6fb770cd285&gt;&#34;, line 76, in &lt;module&gt;
    test_model()
  File &#34;&lt;ipython-input-24-a6fb770cd285&gt;&#34;, line 15, in test_model
    loader = tf.train.import_meta_graph(log_dir+&#39;model.ckpt-40&#39;+ &#39;.meta&#39;)
  File &#34;/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py&#34;, line 1595, in import_meta_graph
    **kwargs)
  File &#34;/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py&#34;, line 499, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File &#34;/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py&#34;, line 308, in import_graph_def
    op_def=op_def)
  File &#34;/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py&#34;, line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File &#34;/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py&#34;, line 1228, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for fp_06_data/nmt_8/
	 [[Node: save_39/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=&#34;/job:localhost/replica:0/task:0/cpu:0&#34;](_recv_save_39/Const_0, save_39/RestoreV2_12/tensor_names, save_39/RestoreV2_12/shape_and_slices)]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[142]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.font_manager</span> <span class="kn">import</span> <span class="n">FontProperties</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">l_a</span><span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="s2">&quot;fp_06_data/loss_track8&quot;</span><span class="p">)</span>
<span class="n">l_b</span><span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="s2">&quot;fp_02_data/loss_track8&quot;</span><span class="p">)</span>
<span class="k">print</span> <span class="nb">len</span><span class="p">(</span><span class="n">l_a</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">l_b</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">l_a</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">l_b</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">#l_c= load_obj(&quot;DATA/loss_track_c&quot;)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">l_a= load_obj(&quot;DATA/loss_track_a&quot;)</span>
<span class="sd">l_b= load_obj(&quot;DATA/loss_track_b&quot;)</span>
<span class="sd">l_c= load_obj(&quot;DATA/loss_track_c&quot;)</span>
<span class="sd">l_58= load_obj(&quot;DATA/loss_track_58&quot;)</span>
<span class="sd">l_59= load_obj(&quot;DATA/loss_track_59&quot;)</span>
<span class="sd">l_61= load_obj(&quot;DATA/loss_track_61&quot;)</span>
<span class="sd">l_62= load_obj(&quot;DATA/loss_track_62&quot;)</span>
<span class="sd">while len(l_c)&lt; len(l_b):</span>
<span class="sd">    l_c.append(0)</span>
<span class="sd">#l_128</span>
<span class="sd">batches = 35000/51</span>
<span class="sd">ticks = [(batches*i, i) for i in range(1,51)]</span>
<span class="sd">fig = plt.figure()</span>

<span class="sd">plt.plot(30*np.arange(0,len(l_c)),l_c, label=&#39;$P_f=0$&#39;)</span>
<span class="sd">#plt.</span>
<span class="sd">fig = plt.figure()</span>
<span class="sd">T = 100*np.arange(0,len(l_58))</span>
<span class="sd">plt.plot(30*np.arange(0,len(l_a)),l_a, label=&#39;$P_f=1$&#39; )</span>
<span class="sd">plt.plot(30*np.arange(0,len(l_b)),l_b, label=&#39;$P_f=0.5$&#39;)</span>
<span class="sd">plt.plot(T,l_62, label=r&quot;$P_f=0.2$&quot;)</span>
<span class="sd">plt.plot(30*np.arange(0,len(l_c)),l_c, label=&#39;$P_f=0$&#39;)</span>
<span class="sd">plt.plot(T,l_58, label=r&quot;$N_h=512$ annealed&quot;)</span>
<span class="sd">plt.plot(T,l_59, label=r&quot;$N_h=256$ annealed&quot;)</span>

<span class="sd">#plt.plot(T,l_61, label=r&quot;$N_h=256$, $P_f=0.2$&quot;)</span>

<span class="sd">plt.legend(loc=&#39;upper center&#39;, bbox_to_anchor=(0.5, 1.25),</span>
<span class="sd">          ncol=3, fancybox=True, shadow=True)</span>
<span class="sd">plt.ylabel(&#39;Batch Loss&#39;)</span>
<span class="sd">plt.xlabel(&#39;Batch Number&#39;)</span>
<span class="sd">plt.xlim(0,35000)</span>
<span class="sd">plt.ylim(0,6)</span>
<span class="sd">plt.show()</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>1112 1045
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt output_prompt">Out[142]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;\nl_a= load_obj(&#34;DATA/loss_track_a&#34;)\nl_b= load_obj(&#34;DATA/loss_track_b&#34;)\nl_c= load_obj(&#34;DATA/loss_track_c&#34;)\nl_58= load_obj(&#34;DATA/loss_track_58&#34;)\nl_59= load_obj(&#34;DATA/loss_track_59&#34;)\nl_61= load_obj(&#34;DATA/loss_track_61&#34;)\nl_62= load_obj(&#34;DATA/loss_track_62&#34;)\nwhile len(l_c)&lt; len(l_b):\n    l_c.append(0)\n#l_128\nbatches = 35000/51\nticks = [(batches*i, i) for i in range(1,51)]\nfig = plt.figure()\n\nplt.plot(30*np.arange(0,len(l_c)),l_c, label=\&#39;$P_f=0$\&#39;)\n#plt.\nfig = plt.figure()\nT = 100*np.arange(0,len(l_58))\nplt.plot(30*np.arange(0,len(l_a)),l_a, label=\&#39;$P_f=1$\&#39; )\nplt.plot(30*np.arange(0,len(l_b)),l_b, label=\&#39;$P_f=0.5$\&#39;)\nplt.plot(T,l_62, label=r&#34;$P_f=0.2$&#34;)\nplt.plot(30*np.arange(0,len(l_c)),l_c, label=\&#39;$P_f=0$\&#39;)\nplt.plot(T,l_58, label=r&#34;$N_h=512$ annealed&#34;)\nplt.plot(T,l_59, label=r&#34;$N_h=256$ annealed&#34;)\n\n#plt.plot(T,l_61, label=r&#34;$N_h=256$, $P_f=0.2$&#34;)\n\nplt.legend(loc=\&#39;upper center\&#39;, bbox_to_anchor=(0.5, 1.25),\n          ncol=3, fancybox=True, shadow=True)\nplt.ylabel(\&#39;Batch Loss\&#39;)\nplt.xlabel(\&#39;Batch Number\&#39;)\nplt.xlim(0,35000)\nplt.ylim(0,6)\nplt.show()\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[138]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">preds_BM</span><span class="p">,</span> <span class="n">targs_BM</span> <span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="s2">&quot;DATA/BM_translated_test&quot;</span><span class="p">),</span> <span class="n">load_obj</span><span class="p">(</span><span class="s2">&quot;DATA/BM_target&quot;</span><span class="p">)</span>
<span class="k">print</span> <span class="nb">len</span><span class="p">(</span><span class="n">preds_BM</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>24911
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[139]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">BLEU_analysis</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">,</span> <span class="n">Ngram_len</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">lab</span><span class="o">=</span><span class="s2">&quot;NMT&quot;</span><span class="p">):</span>
    <span class="n">bleu</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">):</span>
        <span class="n">BLEU4</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">([</span><span class="n">a</span><span class="p">],</span> <span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span><span class="mf">0.25</span><span class="p">))</span>
        <span class="n">BLEU2</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">([</span><span class="n">a</span><span class="p">],</span> <span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))</span>
        <span class="n">BLEU1</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">([</span><span class="n">a</span><span class="p">],</span> <span class="p">[</span><span class="n">p</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">l</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">l</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bleu</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">bleu</span><span class="p">[</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">bleu</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">eval</span><span class="p">(</span><span class="s2">&quot;BLEU&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">Ngram_len</span><span class="p">)))</span>
    <span class="n">BLEU4</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">targs</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span><span class="mf">0.25</span><span class="p">))</span>
    <span class="n">BLEU2</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">targs</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">BLEU1</span> <span class="o">=</span> <span class="n">bleu_score</span><span class="o">.</span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">targs</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">bleu_mean</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">bleu</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">X</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">max</span><span class="p">(</span><span class="n">bleu</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bleu_mean</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;BLEU&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">Ngram_len</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">print</span><span class="s1">&#39;{} Corpus BLEU4: {} </span><span class="se">\t</span><span class="s1"> BLEU2: {} </span><span class="se">\t</span><span class="s1"> BLEU1: {}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lab</span><span class="p">,</span> <span class="n">BLEU4</span><span class="p">,</span> <span class="n">BLEU2</span><span class="p">,</span> <span class="n">BLEU1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">BLEU1</span><span class="p">,</span> <span class="n">BLEU2</span><span class="p">,</span> <span class="n">BLEU4</span>


<span class="n">nmt_02_data</span> <span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="s2">&quot;fp_02_data/PREDICTIONS8&quot;</span><span class="p">)</span>
<span class="n">preds</span><span class="p">,</span> <span class="n">targs</span> <span class="o">=</span> <span class="n">nmt_02_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nmt_02_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">BLEU_analysis</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">)</span>
<span class="k">print</span> <span class="nb">len</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>

<span class="n">nmt_06_data</span> <span class="o">=</span> <span class="n">load_obj</span><span class="p">(</span><span class="s2">&quot;fp_06_data/PREDICTIONS8&quot;</span><span class="p">)</span>
<span class="n">preds</span><span class="p">,</span> <span class="n">targs</span> <span class="o">=</span> <span class="n">nmt_06_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nmt_06_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">BLEU_analysis</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NMT Corpus BLEU4: 0.00750688655243 	 BLEU2: 0.0609424657418 	 BLEU1: 0.186971357143

1085
</pre>
</div>
</div>

<div class="output_area">

<div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>NMT Corpus BLEU4: 0.0051306783277 	 BLEU2: 0.0573189823353 	 BLEU1: 0.194453530706

</pre>
</div>
</div>

<div class="output_area">

<div class="prompt output_prompt">Out[139]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(0.19445353070615168, 0.057318982335335944, 0.005130678327700388)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[136]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">BLEU_analysis</span><span class="p">(</span><span class="n">preds_BM</span><span class="p">,</span> <span class="n">targs_BM</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-136-b6385fd0d239&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> 
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>BLEU_analysis<span class="ansi-blue-fg">(</span>preds_BM<span class="ansi-blue-fg">,</span> targs_BM<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-135-8c6145cba2b7&gt;</span> in <span class="ansi-cyan-fg">BLEU_analysis</span><span class="ansi-blue-fg">(preds, targs, Ngram_len, lab)</span>
<span class="ansi-green-intense-fg ansi-bold">     12</span>         bleu<span class="ansi-blue-fg">[</span>l<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>append<span class="ansi-blue-fg">(</span>eval<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;BLEU&#34;</span><span class="ansi-blue-fg">+</span>str<span class="ansi-blue-fg">(</span>Ngram_len<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     13</span>     BLEU4 <span class="ansi-blue-fg">=</span> bleu_score<span class="ansi-blue-fg">.</span>corpus_bleu<span class="ansi-blue-fg">(</span>targs<span class="ansi-blue-fg">,</span> preds<span class="ansi-blue-fg">,</span> weights<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0.25</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0.25</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">0.25</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0.25</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 14</span><span class="ansi-red-fg">     </span>BLEU2 <span class="ansi-blue-fg">=</span> bleu_score<span class="ansi-blue-fg">.</span>corpus_bleu<span class="ansi-blue-fg">(</span>targs<span class="ansi-blue-fg">,</span> preds<span class="ansi-blue-fg">,</span> weights<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0.5</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0.5</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     15</span>     BLEU1 <span class="ansi-blue-fg">=</span> bleu_score<span class="ansi-blue-fg">.</span>corpus_bleu<span class="ansi-blue-fg">(</span>targs<span class="ansi-blue-fg">,</span> preds<span class="ansi-blue-fg">,</span> weights<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     16</span>     bleu_mean <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>np<span class="ansi-blue-fg">.</span>mean<span class="ansi-blue-fg">(</span>v<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> v <span class="ansi-green-fg">in</span> bleu<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">]</span>

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/nltk/translate/bleu_score.pyc</span> in <span class="ansi-cyan-fg">corpus_bleu</span><span class="ansi-blue-fg">(list_of_references, hypotheses, weights, smoothing_function, auto_reweigh, emulate_multibleu)</span>
<span class="ansi-green-intense-fg ansi-bold">    160</span>         <span class="ansi-red-fg"># denominator for the corpus-level modified precision.</span>
<span class="ansi-green-intense-fg ansi-bold">    161</span>         <span class="ansi-green-fg">for</span> i<span class="ansi-blue-fg">,</span> _ <span class="ansi-green-fg">in</span> enumerate<span class="ansi-blue-fg">(</span>weights<span class="ansi-blue-fg">,</span> start<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 162</span><span class="ansi-red-fg">             </span>p_i <span class="ansi-blue-fg">=</span> modified_precision<span class="ansi-blue-fg">(</span>references<span class="ansi-blue-fg">,</span> hypothesis<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    163</span>             p_numerators<span class="ansi-blue-fg">[</span>i<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">+=</span> p_i<span class="ansi-blue-fg">.</span>numerator
<span class="ansi-green-intense-fg ansi-bold">    164</span>             p_denominators<span class="ansi-blue-fg">[</span>i<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">+=</span> p_i<span class="ansi-blue-fg">.</span>denominator

<span class="ansi-green-fg">/usr/local/lib/python2.7/site-packages/nltk/translate/bleu_score.pyc</span> in <span class="ansi-cyan-fg">modified_precision</span><span class="ansi-blue-fg">(references, hypothesis, n)</span>
<span class="ansi-green-intense-fg ansi-bold">    298</span>         <span class="ansi-green-fg">for</span> ngram <span class="ansi-green-fg">in</span> counts<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    299</span>             max_counts[ngram] = max(max_counts.get(ngram, 0),
<span class="ansi-green-fg">--&gt; 300</span><span class="ansi-red-fg">                                     reference_counts[ngram])
</span><span class="ansi-green-intense-fg ansi-bold">    301</span> 
<span class="ansi-green-intense-fg ansi-bold">    302</span>     <span class="ansi-red-fg"># Assigns the intersection between hypothesis and references&#39; counts.</span>

<span class="ansi-green-fg">/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/collections.pyc</span> in <span class="ansi-cyan-fg">__missing__</span><span class="ansi-blue-fg">(self, key)</span>
<span class="ansi-green-intense-fg ansi-bold">    477</span>         self<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    478</span> 
<span class="ansi-green-fg">--&gt; 479</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">def</span> __missing__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> key<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    480</span>         <span class="ansi-blue-fg">&#39;The count of elements not in the Counter is zero.&#39;</span>
<span class="ansi-green-intense-fg ansi-bold">    481</span>         <span class="ansi-red-fg"># Needed so that self[missing_item] does not raise KeyError</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Building-the-network">Building the network<a class="anchor-link" href="#Building-the-network">&#194;&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Results">Results<a class="anchor-link" href="#Results">&#194;&#182;</a></h1><p>With a <code>feed_previous</code> probability of 0.7, where 70% of the decoder inputs are previously generated tokens, after only around 6 epochs the model is making predictions which are more accurate than some of the data, for example:</p>
<p><code>Source: scrutin du jour du lendemain le h 9 
actual: there is a tie or difference between first 2 candidates is less than 10 votes - 
predicted:  9 are no day in a between the day months</code></p>
<p>where the English translation is is totally incorrect and is obviously just some error in the dataset, however the NMT prediction is in the right ball-park. The google translate answer is "9:00 am the day after polling day".</p>
<p>After 12 epochs, the model makes predictions with a very similar meaning to the correct translation but expressed differently</p>
<p><code>Actual: some 15 of the park's native mammal species are considered rare threatened or endangered 
predicted: several of percent the species's marine mammal species are rare threatened or or endangered</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
